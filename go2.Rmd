---
title: "Estimating differences in scale for high throughput sequencing analysis with ALDEx2"
shorttitle: "Scale ALDEx2"
author:
- name: Greg Gloor, Michelle Pistner Nixon, Justin Silverman
  affiliation: Dep't of Biochemistry, University of Western Ontario, Penn State
  email: ggloor@uwo.ca
bibliography: /Users/ggloor/Library/texmf/bibtex/bib/bibdesk_refs.bib
output:
  BiocStyle::pdf_document: default
package: ALDEx2
abstract: |
    Introduction to scale simulation and FDR correction with ALDEx2.
---
# scale simulation for the no-math crowd

Beyond compositionally in high throughput sequencing; estimating the importance of scale in data analysis

# Introduction

High throughput sequencing (HTS) analysis is commonly used to read out many different types of experimental designs; bulk and single-cell transcriptomics, amplicon and shotgun metagenomics, in vitro selection experiments, and more. There are many analysis tools that are purpose-built for each experimental design and that work well when all assumptions are fulfilled. However, different tools make different assumptions about the underlying data and when the tools fail, they usually fail without error. 

Despite the variety, all tools and analyses suffer from two common issues. First, that many features are statistically significantly different between groups even though the measured difference is very small. Second, that the results can be skewed if the underlying dataset has an asymmetric distribution between the groups. Here we show that both of these issues can be resolved by modelling the size, or scale, of the data in the underlying environment. 

It is instructive to understand how the data are generated. HTS starts by making a 'library' which is a fixed-size sample from the environment. The library is usually combined with other libraries through 'multiplexing' where  the goal is to combine the libraries such that each library contributes equivalent numbers of molecules to the pool. Finally, a fixed number of molecules is sampled from the pooled samples and loaded onto the instrument. Thus, the process of sequencing is akin to taking a poll (making a library), combining polls (multiplexing into a pool) and taking a poll of the pool. It should be clear that this process removes any relationship between actual numbers in the environment and the actual number of molecules actually sequenced. Thus, the total number of molecules that are sequenced for a sample is simply a nuisance parameter. 

All HTS data must be standardized and normalized after sequencing to make the different samples comparable because the total count per sample is non-informative. All of these normalizations are ratios but there are two main main approaches to identifying the denominator.  The first class of normalization uses a denominator that is internal to each sample. This can be as simple as converting the counts to proportions; i.e., by dividing the count for each feature in a sample by the total count of the sample. Derivatives of this method include the TPM (transcripts per million), FPKM( fragments per million), and RPKM (reads per kilobase per million) [@Mortazavi:2008]. In these approaches the proportion is multiplied by several constants that depend on the instrument, gene characteristics in the sample and the sequencing depth. These normalizations track closely the counts of genes determined using fluorescent hybridization methods, with typical correlations above 0.8 [@Moffitt:2016aa,@Taniguchi:2010aa].  The other internal-only normalization is the CLR (centred log-ratio) transform[@aitchison1982]. Here, the count of each feature in each sample is divided by the geometric mean of the counts in the sample with a logarithm being taken of the resulting ratio. In this case, a small pseudo-count or prior is first applied since a log(0) is undefined. The second class of normalization uses a denominator that is determined from data external to the sample being normalized, but that is still derived only from the sequencing data itself. Normalizations such as the RLE (relative log expression)[@Anders:2010], TMM (trimmed mean of M values)[@Robinson:2010a] and CSS (cumulative sum scaling)[@Paulson:2013aa] methods assume that a majority of the features are invariant and that a relative scale can be determined for each sample by dividing by a correction factor. These normalizations specifically normalize the read counts for each feature to a common total so that the counts can be compared between samples directly. In particular the TMM normalization was intended to account for asymmetry in occurrance or abundance in one group relative to the other, but assumes that the majority of features are invariant [@Robinson:2010a]. Note that the CLR normalization also assumes that a majority of the parts are invariant [@Wu2021].

A final complication arises during analysis when logarithmic transformations may or may not be applied, and the CLR is the only transformation that explicitly uses log-transformed data as the starting point. Several groups have pointed out that apparent differences between the behaviour of individual normalizations [@Paulson:2013aa, @Skinnider:2019vc] can be largely explained by differential application of logarithms [@Costea:2014aa, @erb:pc2020]. Indeed in many datasets a logarithm of one of these transforms exhibits behaviours that is similar to the logarithm of one or more other transforms [@GloorAJS2023]. Finally, each normalization is a point estimate of the appropriate denominator and so an additional assumption is that the denominator is a good estimator of the measure. 

These tranformations along with the process of sequencing itself remove all but the relative variation between samples in the dataset. Nevertheless, data that are generated by sequencing come from systems where scale is usually important and may be a confounding variable [@Lovell:2015]. For example, cells transformed by the cMyc oncogene have about 3 times the amount of mRNA and about twice the rRNA content than do non-transformed cells [@Nie:2012aa], and this dramatically skews transcriptome analysis [@Loven:2012aa]. In addition, wild-type and mutant strains of cell lines, yeast or bacteria often have different growth rates, which would affect our ability to identify truly differentially abundant genes [@Yoshikawa:2011aa]. As another example, the total bacterial load of the vaginal microbiome differs by 1-2 orders of magnitude in absolute abundance [@Zozaya:2010], and the composition is dramatically different as well [@Ravel:2010,@Hummelen:2010]. Thus, the full description of these systems includes both relative change (composition) and absolute abundance (scale) but we can access only the composition. 

It is enlightening to examine the dispersion or variance of the data as counts and as the logarithm of counts. The counts of data derived from sequencing are overdispersed with the mean value being less than the variance [@Robinson:2010] as seen in Panel A of Figure 1 and this is why most tools model the counts with this distribution. However, the actual analysis is usually performed on the logarithm of the counts [Robinson:2010, Love:2014aa], or on the logarithm of the clr values[@fernandes:2013] and the mean-dispersion distribution of the logarithm of the counts is quite different as shown in panel B of Figure 1 and as noted elsewhere [@fernandes:2013, @Love:2014aa]. 


```{r dispersion, echo=F,warning=F, message=F,comment=F, result=F, fig.cap="Plot of abundance v dispersion for a typical transcriptome dataset as both counts and as logarithms of counts. Panel A shows that the data are over-dispersed relative to a Poisson distribution which is represented by the dashed line when plotted on a log-log scale. Panel B shows that the relationship between the mean and the dispersion, here the standard error (SE) of the mean, is very different when the data are log-transformed first. In addition, the amount of dispersion reaches a minimum at moderate count values. The red line in each panel shows the loess line of fit to the mid-point of the distributions. The dashed orange line in panel A is the line of equivalence, and in panel B is the minimum y value." }
library(DESeq2)
devtools::load_all('~/Documents/0_git/ALDEx_bioc')
#library(ALDEx2)

yst <- read.table('~/Documents/0_git/datasets/transcriptome.txt', header=T, 
  row.names=1)
# remove the one gene with 0 reads

yst <- yst[rownames(yst) != "YOR072W-B",]

# Gierlinski:2015aa
yst[,c('SNF2.6', 'SNF2.13','SNF2.25','SNF2.35')] <- NULL 
yst[,c('WT.21','WT.22','WT.25','WT.28','WT.34','WT.36')] <- NULL  

conds <- c(rep('S', 44), rep('W', 42))
coldata <- data.frame(conds)

# DESeq2
dds <- DESeqDataSetFromMatrix(countData = yst,
          colData = coldata, design= ~ conds)
dds <- DESeq(dds)
resultsNames(dds) # lists the coefficients
res <- results(dds, name="conds_W_vs_S")
set.seed(2023)
#ALDEx2
x <- aldex.clr(yst, conds, gamma=1e-3,verbose=F)
x.e <- aldex.effect(x, include.sample.summary=T, verbose=F)
x.t <- aldex.ttest(x, verbose=F)
set.seed(2023)
x.s <- aldex.clr(yst, conds, gamma=1, verbose=F)
x.s.e <- aldex.effect(x.s, include.sample.summary=T, verbose=F)
x.s.t <- aldex.ttest(x.s, verbose=F)

sig.des <- which(res@listData$padj < 0.01)
sig.ald <- which(x.t$we.eBH < 0.01)
sig.s.ald <- which(x.s.t$we.eBH < 0.01)

# get and plot mean/var or mean/SE for counts
# and log counts
yst.mn <- apply(yst, 1, mean)
yst.mn.log <- apply(yst, 1, function(x) mean(log2(x)))
yst.mn.log[is.infinite(yst.mn.log)] <- 0

yst.v <- apply(yst, 1, var)

par(mfrow=c(1,2))
plot(log2(yst.mn), log2(yst.v), pch=19, cex=0.5, col=rgb(0,0,0,0.2),
  xlab='Mean count', ylab='Variance')
def <- data.frame(log2(yst.mn),log2(yst.v))
lines(lowess(def, f=0.1), col=2, lwd=2)
title('A: Mean vs. Variance', adj=0, line= 0.8)
abline(0,1, col=rgb(1,0.6,0,0.5), lwd=2, lty=2)

l.df <- data.frame(yst.mn.log, res@listData$lfcSE)
plot(l.df, pch=19, cex=0.5, col=rgb(0,0,0,0.2),
  xlab='Mean log2(count)', ylab='SE log2(count)',ylim=c(0,0.4))
lines(lowess(l.df), col=2, lwd=2)
abline(h=min(lowess(l.df)$y), col=rgb(1,0.6,0,0.5), lwd=2, lty=2)
title('B: log2 Mean vs. log2 Variance', adj=0, line= 0.8)

```

By not accounting for scale we are usually identifying statistically significant changes that are biologically meaningless but are found because of the artificially low dispersion.  As one example, recent guidance suggests \emph{using only a  small number of samples} for bulk RNA-sequencing because  only a few samples is needed to identify the majority of statistically significant features found with a large sample size [@Schurch:2016aa]. This popularized the useage of both p-values and log2 fold change between groups as dual cutoffs when determining significance. However, it is also possible to fail to identify true positive differences because of scale [@nixon2023scale].

Clearly we need some way to account for the variation in, and effect of, the scale of the underlying systems [@nixon2023scale] when determining differential abundance (DA) using high throughput sequencing. While normalizaitons attempt to correct for differences in relative counts, no tool accounts for differences in the intrinsic or extrinsic scale of the underlying system. Moreover, while we cannot measure scale directly, we can estimate its effect post-hoc on results. 
  
# Results - examples:

We can model the conundrum of scale by assuming that the true values from the system that we want to measure are counts  composed of both compositional and total values, and that their product is the full scaled system that fits the equation: \(W = W^{\parallel}W^{\perp}\). If the true data have $D$ features (genes, taxa, etc) and $N$ samples, then  $W$ is a $D \times N$ matrix of values and we can denote the true  count of a feature in a sample as \(W_{dn}\). However, sequencing only does not allow us to access \(W^{\parallel}\) directly, but instead returns only a single estimate of the composition for each feature \(Y^{\parallel}_{dn}\). This single value is not definitive since different technical replicates  return different numbers for \(Y^{\parallel}_{dn}\) because of sampling variation [@Marioni:2008,@fernandes:2013]. 

We can use Bayesian techniques to estimate both the sampling variation of \(W^{\parallel}\) and the scale uncertainty of \(W^{\perp}\) by Monte Carlo sampling with the ALDEx2 R package. ALDEx2 generates pseudo technical replicates of \(Y^{\parallel}\) by Monte Carlo sampling from a Dirichlet distribution to produce a posterior distribution for \(Y^{\parallel}\) that is  an estimate of \(W^{\parallel}\)[@fernandes:2013,@gloorAJS:2016]. Then a CLR transformation is applied to each Monte Carlo sample to produce a distribution of log-ratio transformed values. Crucially, the denominator used for the CLR can be seen as a point estimate of the scale of the system [@nixon2023scale]. Thus, modifying ALDEx2 by replacing the point estimate for the CLR denominator with Monte Carlo sampled values from a log-Normal distribution gives a distribution of credible denominators. Thus, the CLR values now are credible estimates for both  \(W^{\parallel}\) and \(W^{\perp}\). This allows the scaled CLR distribution to be used to estimate the effect of scale on the output and so make \(Y \sim W\) under the assumption of the scale uncertainty. Below we use two example datasets to show how including scale uncertainty can be used to make inferences about differentially abundant features more reliable.
 
The first dataset is a highly replicated yeast transcriptome where one condition is wild-type and the other has a snf-1 gene knocK0ut[@Gierlinski:2015aa]. Yeast deficient for snf-1 grow more slowly and are sensitive to a variety of common agents that cause cell stress [@Yoshikawa:2011aa]. This dataset has been used to argue that only a small number of replicates need to be used to identity differentially abundant genes and that different tools should be used for datasets with different sample sizes because the tools have different intrinsic statistical power [@Schurch:2016aa]. This guidance runs counter to standard statistical practice where power is intrinsically linked to sample size [@Halsey:2015aa], yet is entrenched in all fields that use HTS as an experimental readout. 

Using either DESeq2 or ALDEx2, we observe that a majority of transcripts are statistically significantly different between groups even with a FDR of 0.01 ;`r length(sig.des)` or `r length(sig.ald)` of `r nrow(yst)` transcripts. Applying the rule of thumb of at least a $2^{1.4}$ fold change reduces these outputs to `r length(which(res@listData$padj < 0.01 & abs(res@listData$log2FoldChange) > 1.4))` for DESeq2 and to `r length(which(x.t$we.eBH < 0.01 & abs(x.e$diff.btw) > 1.4))` for ALDEx2. Clearly, the necessary assumption of most features being invariant is not justified. 

As shown in Figure 2 A,B,D,E the root cause of the many statistically significant positive transcripts is the very large number of transcripts with negligible variance with both DESeq2 and ALDEx2. We can see that almost all the transcripts that are differentially abundant with an FDR < 0.01 (orange and red points) have extremely low dispersion and a very low difference between groups. In the most extreme cases transcripts with near 0 difference have a low FDR. This issue lead to the common practice of choosing transcripts with a low FDR and a fold-change threshold (commonly set at $\pm 2^{1.4}$), and these limits are shown by the dashed grey lines. A similar sitation arises when using the ALDEx2 package, and indeed the two methods identify substantially similar transcripts. This results begs the question, "why bother with the signficance test?".

The very low dispersion estimate for most of the features  arises because  scale variation in the underlying data has been removed through sequencing and normalization. The actual scale of the data is unaccessible post-sequencing but we can estimate the effect of scale on the output. To do this, we add uncertainty to the denominator that is used to calculate the log-ratio of the samples, and combine this with the posterior probabilities that ALDEx2 calculates on a per-feature basis [@fernandes:2013]. Scale uncertainty is incorporated using the `gamma` parameter that controls the amount uncertainty being included when we call either `aldex()`, or `aldex.clr()`. The `ALDEx2` package contains a sensitivity analysis function, `aldex.senAnalysis()`, that can be used to explore the effect of different amounts of scale uncertainty. In practice we suggest that a `gamma` parameter between 0.5 and 1 is realistic for most experimental designs.

Applying `gamma=1` as a parameter we can see that the large number of transcripts with near 0 dispersion have had their dispersion increased (Figure 2C), and this results in many fewer transcripts (`r length(sig.s.ald)`) being called significantly different  as shown in the volcano plot in Figure 1F (red points). Furthermore, overplotting the significant transcripts identified after adding scale uncertainty on the un-scaled analysis shows that adding scale uncertainty removes the need for the dual cutoff.  Indeed, adding scale uncertainty reduces the significant transcripts to approximately the number observed with the somewhat arbitrary difference cutoff. Thus, incorporating scale uncertainty through the default scale model allows us to determine which variables are likely to be significant due to sequencing and normalization, and which are significantly different even with scale uncertainty included.
  
```{r plot1, echo=F, fig.cap="Effect and volcano plots for unscaled and scaled transcriptome analysis. DESeq2 or ALDEx2 were used to conduct a differential abundance (DA) analysis on the yeast transcriptome dataset. The results were plotted to show the relationship between difference and dispersion (effect plot) or difference and the Benjamini-Hochberg corrected p-values (volcano plot). Panels A,B,D,E are for the unscaled analysis, and Panels C,F are for the scaled analysis. Each point represents the values for one transcript, with the color indicating if that transcript was significant in the scaled analysis and unscaled analysis (red) or in the unscaled analysis only (orange). Points in grey are not statistically signficantly different with any analysis. The horizontal dashed lines represent a log2(difference) of 1.4, which is a commonly applied cutoff when the majority of features are statistically significant."}
par(mfrow=c(2,3))
plot(res@listData$lfcSE*sqrt(ncol(yst)), res@listData$log2FoldChange, xlim=c(0,5), 
  col=rgb(0,0,0,0.1), xlab='LFC SD', ylab='log2 Difference')
title('A: DESeq2 effect', adj=0, line= 0.8)
points(res@listData$lfcSE[sig.des]*sqrt(ncol(yst)),
  res@listData$log2FoldChange[sig.des], col=rgb(1,.66,0,0.5), 
  pch=19, cex=0.5)
points(res@listData$lfcSE[sig.s.ald]*sqrt(ncol(yst)),
  res@listData$log2FoldChange[sig.s.ald], col=rgb(1,0,0,0.5), 
  pch=19, cex=0.5)
abline(h=c(-1.4,1.4), lty=2, col='grey')

plot(x.e$diff.win, x.e$diff.btw, col=rgb(0,0,0,0.1), 
   xlab='Dispersion', ylab='log2 Difference')
title('B: ALDEx2 effect', adj=0, line= 0.8)
points(x.e$diff.win[sig.ald], x.e$diff.btw[sig.ald], 
  col=rgb(1,.66,0,0.3), cex=0.5, pch=19)
    abline(h=c(-1.4,1.4), lty=2, col='grey')
points(x.e$diff.win[sig.s.ald], x.e$diff.btw[sig.s.ald], 
  col=rgb(1,0,0,0.6), cex=0.5, pch=19)
    abline(h=c(-1.4,1.4), lty=2, col='grey')

plot(x.s.e$diff.win, x.s.e$diff.btw, col=rgb(0,0,0,0.1),
   xlab='Dispersion', ylab='log2 Difference', xlim=c(0.1,5))
title('C: ALDEx2 scaled effect', adj=0, line= 0.8)
points(x.s.e$diff.win[sig.s.ald], x.s.e$diff.btw[sig.s.ald], 
  col=rgb(1,0,0,0.5), cex=0.5, pch=19)
    abline(h=c(-1.4,1.4), lty=2, col='grey')

# volcano
plot(res@listData$log2FoldChange,-1*log10(res@listData$padj + 1e-300), 
  col=rgb(0,0,0,0.1), xlab='log2 Difference', ylab='-1 log10(p.adjust)')
title('D: DESeq2 volcano', adj=0, line= 0.8)
points(res@listData$log2FoldChange[sig.des],-1*log10(res@listData$padj[sig.des] + 1e-300), col=rgb(1,.66,0,0.3), 
  pch=19, cex=0.5)
points(res@listData$log2FoldChange[sig.s.ald],-1*log10(res@listData$padj[sig.s.ald] + 1e-300), col=rgb(1,0,0,1), 
  pch=19, cex=0.5)
  abline(v=c(-1.4,1.4), lty=2, col='grey')

plot(x.e$diff.btw, -1*log10(x.t$we.eBH +1e-70), col=rgb(0,0,0,0.1), 
   xlab='log2 Difference', ylab='-1 log10(p.adjust)')
title('E: ALDEx2 volcano', adj=0, line= 0.8)
points(x.e$diff.btw[sig.ald], -1*log10(x.t$we.eBH[sig.ald]  +1e-70), 
  col=rgb(1,.66,0,.3), cex=0.5, pch=19)
points(x.e$diff.btw[sig.s.ald], -1*log10(x.t$we.eBH[sig.s.ald]  +1e-70), 
  col=rgb(1,0,0,1), cex=0.5, pch=19)
abline(v=c(-1.4,1.4), lty=2, col='grey')


plot(x.s.e$diff.btw, -1*log10(x.s.t$we.eBH +1e-15), col=rgb(0,0,0,0.1),
   xlab='log2 Difference', ylab='-1 log10(p.adjust)')
title('F: ALDEx2 scaled volcano', adj=0, line= 0.8)

points(x.s.e$diff.btw[sig.s.ald], -1*log10(x.s.t$we.eBH[sig.s.ald]+1e-15),
  col=rgb(1,0,0,1), cex=0.5, pch=19)
    abline(v=c(-1.4,1.4), lty=2, col='grey')

```

  
The second example dataset is a vaginal metatranscriptome dataset used in [@Macklaim:2018aa,@Wu2021], where we are comparing gene expression in bacteria collected from healthy (H) and BV-affected women.  In this environment, both the relative abundance of species between groups is different as is the gene expression levels within a species [@macklaim:2013]. We further expect that the total number of bacteria is about 10X more in BV than in H [@Zozaya:2010]. Thus, this is  an extremely challenging environment to determine differential abundance. Indeed, the accepted method to analyze vaginal metatranscriptomes is to conduct a taxon by taxon analysis rather than a system-wide analysis [@macklaim:2013;@Denge00262-18;@Fettweis:2019aa] because a pooled analysis unexpectedly identifies many housekeeping genes as being differentially abundant between groups. 

In this example we show how to specify the scale model explicitly and show that applying different scale models to each group can control for the very large difference in scale in the underlying data. When specifying the whole scale model we can pass a matrix of scale values instead of a single to `aldex.clr()`. This matrix should have the same number of rows as the of Monte-Carlo Dirichlet samples, and the same number of columns as the number of samples. This matrix encapsulates the additional uncertainty of the scale model on a per-sample basis.

Figure 3A shows an effect plot [@gloor:effect] of the data where reads are grouped by function, corresponding approximately to orthologous proteins regardless of the organism of origin. Each point represents one of the 3728 functions, and we can see that there are many more functions represented in the BV group (bottom) than in the healthy group (top). This is because the \textit{Lactobacilli} that dominate a healthy vaginal microbiome have reduced genome content relative to the anaerobic organisms that dominate in BV, because  there is a greater diversity of organisms in BV than in H samples and because the BV condition has at least an order of magnitude more bacteria than does the H condition. 

 We can  see that there are a large number of functions that are shared between the two groups (Figure 3A), and inspection shows that these largely correspond to core metabolic functions that would not be expected  to contribute to differences in ecosystem behaviour. As a proxy for housekeeping functions the core ribosome functions (blue) shows that their mean location is not centred on 0.The major group of these housekeeping functions is located off the line of no difference (being approximately located at +1.5) and not surprisingly have among the lowest dispersion in the dataset. Nevertheless, they are identified as differentially abundant (red) along with many others. While changes in the abundance of housekeeping functions is a useful proxy for relative abundance of species in the environment, they tell us nothing about the functional capacity of the two groups because these are functions in common to every organism. Of more interest is determining the functions that are different between groups that are unique or over-expressed in one group relative to the other.  


```{r ribo, echo=F}
ribo.v <- c("K02863","K02864","K02865","K02866","K02867","K02871","K02872","K02873","K02874","K02876","K02877","K02878","K02879","K02880","K02881","K02883","K02884","K02885","K02886","K02887","K02888","K02890","K02892","K02895","K02897","K02899","K02902","K02904","K02905","K02906","K02907","K02909","K02911","K02913","K02914","K02916","K02920","K02922","K02926","K02931","K02932","K02933","K02935","K02936","K02938","K02939","K02941","K02943","K02945","K02946","K02948","K02949","K02950","K02952","K02954","K02955","K02956","K02959","K02961","K02963","K02964","K02965","K02967","K02968","K02969","K02970","K02975","K02981","K02982","K02984","K02986","K02987","K02988","K02990","K02991","K02992","K02994","K02995","K02996","K02997","K02998","K07590")
```

```{r makeScaleMatrix, echo=T}
aldex.makeScaleMatrix <- function(gamma, diff, conditions){
  ## new scale model
  # mu1 is the base relative variance
  # mu2 is the other relative variance
  # gamma is the dispersion paramenter
  gamma=gamma
  mu1 = 1 # set base to 1
  mu2 = 1 + diff # set other to adjust this until the housekeeping is centred

  # note: it is the log2 difference between mu1 and mu2 that is key here
  # eg; mu1=1, mu2=1.15 is equivalent to mu1=4, mu2=4.6
  # log2(1)=0, log2(1.15)~0.2; log2(4)=2, log2(4.6)~2.2
  
  mu.vec <- gsub(levels(factor(conditions))[1], log2(mu1), conditions)
  mu.vec <- as.numeric(gsub(levels(factor(conditions))[2], log2(mu2), mu.vec))
  return(t( sapply(mu.vec, FUN = function(mu) rlnorm(128, mu, gamma)) ))
}
```

```{r meta, echo=F, warning=F, message=F,comment=F, result=F, fig.cap="Analysis of vaginal transcriptome data aggregated at the Kegg Orthology (KO) functional level. Panel A shows the default analysis with samples from healthy individuals at the top and from BV individuals at the bottom. Highlighed in the box are highly abundant KOs that are almost exlusively housekeeping functions, with ribosomal KOs highlighted in blue,  statistically significant (FDR < 0.01) functions in red, and non-significant functions in black or orange. These housekeeping functions are off the midline of no difference. Panel B shows the same data scaled with `gamma = 1`, which increase the minimum dispersion approximatly by one unit. Here the housekeeping functions from Panel A are colored cyan or blue for reference. Panel C shows the same data scaled with `gamma = 0.75` and a 0.15 fold difference in dispersion applied to the BV samples relative to the H samples. The orange functions are now statistically significant. Note that this shifts the midpoint of the housekeeping functions towards the midline." }

set.seed(2023)
load('~/Documents/0_git/projects/metatranscriptome/Rdata/ko.both.all.Rda')

# make a vector of conditions
conds.K0 <- c(rep('H',8), rep('B',14), rep('B',14), rep('H', 8)) 

xt <- aldex.clr(ko.both.all, conds.K0)
xt.e <- aldex.effect(xt, include.sample.summary=T)
xt.t <- aldex.ttest(xt)
xt.all <- cbind(xt.e, xt.t)

## single gamma model
xg <- aldex.clr(ko.both.all, conds.K0, gamma=1)
xg.e <- aldex.effect(xg)
xg.t <- aldex.ttest(xg)
xg.all <- cbind(xg.e, xg.t)

mu.mod <- aldex.makeScaleMatrix(0.75, .15, conds.K0)
 
xt.m <- aldex.clr(ko.both.all, conds.K0, gamma=mu.mod)
xt.m.e <- aldex.effect(xt.m, include.sample.summary=T)
xt.m.t <- aldex.ttest(xt.m)
xt.m.all <- cbind(xt.m.e, xt.m.t)

hk <- rownames(xt.e)[xt.e$diff.win < 2.5 & xt.e$diff.btw > 0 & xt.e$diff.btw < 3]
hk.off <- xt.e$diff.win < 2.5 & xt.e$diff.btw > 0 & xt.e$diff.btw < 3

fn <- rownames(xt.m.all)[xt.m.all$we.eBH < 0.01 & xt.m.all$diff.btw < 1 & xg.all$we.eBH > 0.01 & xt.all$we.eBH > 0.01]

#par(mfrow=c(1,1))
#plot(density(xt.m.e$diff.btw[hk.off]))
#abline(v=0, col='red')

par(mfrow=c(1,3))
aldex.plot(xt.all, cutoff.pval=0.01)
points(xt.all[ribo.v,'diff.win'], xt.all[ribo.v,'diff.btw'], col='blue', cex=0.5, pch=19)
points(xt.all[fn,'diff.win'], xt.all[fn,'diff.btw'], col='orange', cex=0.5, pch=19)
rect(0.5,0,3,5, col=rgb(0,0,0,0.1), lty=2, lwd=3)
title('A: ALDEx2 unscaled', adj=0, line= 0.8)

aldex.plot(xg.all, xlim=c(0.3,9), cutoff.pval=0.01)
points(xg.all$diff.win[hk.off], xg.all$diff.btw[hk.off], pch=19, cex=0.4, col=rgb(0,1,1,0.5))
points(xg.all[ribo.v,'diff.win'], xg.all[ribo.v,'diff.btw'], col='blue', cex=0.5, pch=19)
points(xg.all[fn,'diff.win'], xg.all[fn,'diff.btw'], col='orange', cex=0.5, pch=19)
title('B: ALDEx2 gamma scaled', adj=0, line= 0.8)


aldex.plot(xt.m.all, xlim=c(0.3,9), cutoff.pval=0.01)
points(xt.m.all$diff.win[hk.off], xt.m.all$diff.btw[hk.off], pch=19, cex=0.4, col=rgb(0,1,1,0.5))
points(xt.m.all[ribo.v,'diff.win'], xt.m.all[ribo.v,'diff.btw'], col='blue', cex=0.5, pch=19)
points(xt.m.all[fn,'diff.win'], xt.m.all[fn,'diff.btw'], col='orange', cex=0.5, pch=19)
title('C: ALDEx2 both scaled', adj=0, line= 0.8)


```

Applying `gamma=1` as before increases the dispersion as expected, but does little to move the large number of housekeeping functions toward the midline of no difference. Nevertheless, about 50% of the housekeeping functions are no longer statistically significantly different. 

Up to this point, scale uncertainty has been applied uniformly to both conditions, but the scale adjustment can be applied to each condition, or even each sample independently through a custom scale matrix. This can be done quite simply with the `aldex.makeScaleMatrix()` function which produces a matrix of scale uncertainties that are distinct for each group. Applying a differential scale of 0.15, or 15% of the base scale now moves the housekeeping functions to the midline of no difference. Differential scale has the property that if the differences in underlying scale of the system is large, then the sign of the differential scale is irrelevant because ... [HELP]. Note that this identifies a significant number of functions that are differentially up in BV that were formerly classed as not different without scale, or when only a uniform  scale was applied. These former false negatives are noted in orange in each panel. Inspection of the functions shows that these are largely missing from the Lactobacillus species and so should actually be captured as differentially abundant. Thus, applying differential scale allows us to distinguish between both false positives (housekeeping functions in cyan) and false negatives (orange functions) even in a very difficult to analyze dataset.

Differential scale has the property that if the differences in underlying scale of the system is large, then the sign of the differential scale is irrelevant.  

# Discussion

Biological count data can be decomposed into two parts the relative (compositional) and the absolute (scale), and the product of these generates a fully scaled biological system [@nixon2023scale]. Biological systems are inherently variable and stochastic and current measurement methods that rely on high throughput sequencing fail to capture all of that variation. In the absence of  information external to the sequencing run itself, no normalisation method can recapture any of the scale information, including scale variation [@Loven:2012aa].

While the underlying scale of the system cannot be measured easily, the effect on analysis can by including scale uncertainty in the analysis [@nixon2023scale]. Nixon et al, showed that this can be done by including uncertainty in the denominator used for the normalization. The ALDEx2 R package is ideally suited for this since this tool builds a Bayesian posterior of the compositional component of the dataset at the outset and then conducts the analysis on that posterior. Adding scale uncertainty can be done at the same time thus producing a posterior model that incorporates both compositional and scale uncertainty. For this, the compositional uncertainty is sampled from a Dirichlet distribution, and the scale uncertainty is sampled from a log-Normal distribution.

All normalizations attempt to make the samples in a dataset commensurate but cannot explicitly address the scale of the underlying system. However, the general lack of scale information has important consequences for the analysis of HTS datasets. One issue is that analysis tools  seem over-powered with even moderate sample sizes  [@Schurch:2016aa]. Using small sample sizes in analysis leads to less reliability and reproducibility in analyses since surprisingly large sample sizes are needed to determine reliable p-values (eg. [@Halsey:2015aa]). Thus, recommendations to use small sample sizes in multivariate datasets such as RNA-seq datasets are not supported by simple modelling in the univariate case. Another issue is that datasets are difficult to analyze when there they contain systematic asymmetry, with different tools exhibiting differing pathologies with these datasets [@Robinson:2010a, @Wu2021].

In the case of overpowering, HTS analyses seem to be more robust when applying a dual cutoff of both p-value and difference between group means [@Schurch:2016aa]. Figure 2 shows one reason for this robustness could be that the dual cutoff is mimicking the effect of including scale uncertainty, since substantially similar transcripts are identified by the two approaches. However, while using the post-hoc difference cutoff is useful for differential abundance analysis it is not clear how this can be incorporated into other kinds of downstream analyses. Conversely data that include scale uncertainty are fully compatible with existing downstream analyses.

In the case of asymmetry, the use of a user-specified scale model can be very useful for otherwise difficult to analyze datasets such as meta-transcriptomes and in-vitro selection datasets where the majority of features can change. We showed one such example in Figure 3 where the dataset was highly asymmetrical, and the TMM and RLE normalizations cannot be used. Incorporating differential scale on a per-group basis moves the mass of the data towards the midline of no difference and so affects both Type I and Type II error rates. Differential scale has the property that if the differences in underlying scale of the system is large, then the sign of the differential scale is irrelevant. In this analysis, transcripts that were previously not classed as differentially abundant are now called as significantly different, and the housekeeping transcripts move from being significantly different to not being identified as such. While we acknowledge that some prior information on which housekeeping transcripts should not be classed as DA is needed, we suggest that this information is widely available and used when performing the gold-standard quantitative PCR test of differential abundance [@Thellin:1999aa,@SEQC/MAQC-III-Consortium:2014aa]. Thus, the use of this prior knowledge is not unique to our approach.

In summary, while the underlying scale of the system is generally inaccessible, the effect of scale on the analysis outcomes can be modelled. Adding scale information to the analysis allows for more robust inference because the features that are sensitive to scale can be identified and their impact on the analysis weighted accordingly. Additionally, the use of differential scale models permits difficult to analyze datasets to be examined in a robust and principled manner even when the majority of features are asymmetrically distributed or expressed (or both) in the groups. Thus, reportin scale uncertainty should become a standard practice in the analysis of HTS datasets as a way to identify which features are most robust to differences in the underlying system. Furhtermore, we supply a set of toosl that make incorporating scale simple even for datasets that come from highly asymmetrical environments. 

   
# Methods or supplement

Count data can in the underlying system be decomposed into two parts; the relative amount (composition) and the total amount (scale). We can describe the full scaled system made up of the composition and the scale with the equation: \(W = W^{\parallel} \dot W^{\perp}\).  What we measure by sequencing is only the composition part  \(Y^{parallel}\) which is a single point estimate of the composition \(W^{parallel}\) of the underlying true system. We can denote the sequence count dataset as an \(D \times N\) matrix, with elements \(Y_{dn}\) indicating the number of sequenced DNA molecules mapping to the \(d^{th}\) entity (e.g., taxa or gene) in the \(n^{th}\) sample. We will use hat notation to denote an estimate of a quantity  (e.g., \(\hat{W}\) is an estimate of \(W\)). 

It is possible that the relative and size information can vary independently. For example, the total number of RNA molecules in a cell may vary by type, but the relative amounts of many of them may be constant; alternatively the total number of molecules may be the same, but the relative proportions may change. Of course, there could be a mixture of both possibilities as well.
  
Making a library from the molecules in \(W\), sequencing and generating the count table from the output provides a single point estimate of \(W^{\parallel}\). The accuracy with which \(Y^{\parallel}\) is a good estimate of \(W^{\parallel}\) is determined by the number of samples, the number of DNA molecules sequenced relative to the size of the system and is affected by the bioinformatic pipelines. Nevertheless, it is assumed that \(Y^{\parallel} \sim W^{\parallel}\) under these constraints.
 
   - \(Y^{\parallel}\) is a point estimate of the data and under-samples the true underlying distribution because of sparse random sampling and because the number of samples sequenced is usually very small. 
   
  - ALDEx2 uses \(Y^{\parallel}_{d.}\) as the basis to generate a posterior distribution by Monte-Carlo sampling from a Dirichlet distribution, where the posterior distribution contains a large number of credible values for \(W^{\parallel}\).
    
  - The Monte-Carlo instances are then CLR transformed. Here the denominator of the CLR is a single point estimate of the underlying scale. 
  
  - ALDEx2 has been modified include Monte-Carlo sampling from a log-Normal distribution to generate a posterior distribution of credible scale values, given the estimated scale in \(W\). The amount of scale is controlled either by providing a single value \(\gamma\) which is the standard deviation (SD) of the scale, or by providing a matrix of SDs that vary between groups. 
  
  - This has the result of further smoothing and broadening the distribution to account for the uncertainty in the scale of the system from which the data was drawn.
  
  - Applying uniform scale uncertainty increases the dispersion of the 
 
  So in formal terms, the system we want to measure is a set of N samples with D parts (genes, species, etc) contained in a matrix or data table W. The observed data is in a matrix Y, which contains the same 
  We incorporate measurement uncertainty as uncertainty around the observed value
  We incorporate scale uncertainty as uncertainty around the correction used (Gx)
  	- contant uncertainty increases dispersion
  	- different amounts of uncertainty increases dispersion and moves the center
 
    
    
    
