Nice paper by Nishijima et al, from Bork's lab using machine learning to show that the absolute bacterial load is a major confounder in most human microbiome studies. Now seems a good time to outline the  approaches that we have developed.

That the total bacterial load confounds analysis is not a new observation, but the scope of the problem is breathtaking and is not limited to microbiome work. We call this the scale problem. Read on for how to address it analytically.

The scale of a system is the total number of measurable items (bacteria, genes, transcripts, etc) and almost all normalization methods in use have implicitly or explicitly estimated scale - but they have done so badly.

Silverman and colleagues showed in a number of submitted papers that the log-ratio approach made implicit scale assumption that while often wrong was at least interpretable as a scale estimate. 

This initial poor scale estimate could be improved in multiple ways. Furthermore, it generalized to other types of high throughput sequencing data including transcriptomics, metagenomics, metatranscriptomics and in-vitro selection experiments.

First, including an estimate of scale uncertainty reduced false positive identification of taxa in microbiome studies. They did this by modifying the ALDEx2 tool to generate scale simulated random variables (SSRVs) instead of compositional estimates.

Second, they showed that external abundance information could be included in the scale model built by ALDEx2 to both reduce  false positive identifications and also improve true postive identification of taxa.

Third, they showed that an interval-based approach could improve the rigor and robustness of these analyses.

Using this approach we conducted a robust analysis of the human vaginal metatranscriptome where absolute bacterial abundance and the species both vary widely. We found new insights into host-microbe and microbe-microbe interactions in this system. 

 