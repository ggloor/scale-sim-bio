---
title: "Beyond compositionally in high throughput sequencing; estimating the importance of scale in data analysis with ALDEx2
"
shorttitle: "Scale ALDEx2"
author:
- name: Greg Gloor
  affiliation: Dep't of Biochemistry, University of Western Ontario
  email: ggloor@uwo.ca
- name: Michelle Pistner Nixon
  affiliation: College of Information Sciences and Technology, Pennsylvania  State University
- name: Justin Silverman
  affiliation: College of Information Sciences and Technology, Department of Statistics, Department of Medicine, Pennsylvania  State University
bibliography: /Users/ggloor/Library/texmf/bibtex/bib/bibdesk_refs.bib
output:
  BiocStyle::pdf_document: default
package: ALDEx2
abstract: |
    Introduction to scale simulation and FDR correction with ALDEx2.
---

# Introduction

High throughput sequencing (HTS) is a universal tool to explore many biological phenomenon such as gene expression (single-cell sequencing, RNA-sequencing, meta-transcriptomics), microbial community composition (16S rRNA gene sequencing, shotgun metagenomics) and differential enzyme activity (selex, CRISPR killing). HTS proceeds by taking a fixed-number sample from the environment, making a library, multiplexing (merging) multiple libraries and applying a fixed number of molecules to the flow cell. In essence it is a poll of the environment that is mixed with other polls and then a poll of the mixture is taken. It should be clear that the total number of molecules sequenced is driven by the capacity of the instrument and not by the number of molecules in the sampled environment.

Data that are generated by sequencing come from systems where scale is usually important and may be a confounding variable [@Lovell:2015]. For example, cells transformed by the cMyc oncogene have about 3 times the amount of mRNA and about twice the rRNA content than do non-transformed cells [@Nie:2012aa], and this dramatically skews transcriptome analysis [@Loven:2012aa]. In addition, wild-type and mutant strains of cell lines, yeast or bacteria often have different growth rates, which would affect our ability to identify truly differentially abundant genes [@Yoshikawa:2011aa]. As another example, the total bacterial load of the vaginal microbiome differs by 1-2 orders of magnitude in absolute abundance [@Zozaya:2010], and the composition is dramatically different as well [@Ravel:2010;@Hummelen:2010]. Thus, the full description of these systems includes both relative change (composition) and absolute abundance (scale) but we can access only the composition directly. 

More formally, if the true information in the  environment being sampled can be summarized by counts of features (genes, taxa, etc) in a matrix, then the elements of the matrix can be decomposed into its composition (relative information) and its scale (total sum). We can formally state this as \(\mathbf{W} = \mathbf{W}^{\parallel} \times \mathbf{W}^{\perp}\). If the matrix has \(N\) samples and \(D\) parts, then we can uniquely identify \(\mathbf{W}_{dn}\) as the \(d^{th}\) feature in sample \(n\).  Any data that we collect by sequencing is thought to contain only proportional information and we can represent the corresponding sequenced matrix as \(\mathbf{Y}\). Compositional data analysis makes the strong assumption  that \(\mathbf{Y}_{n} = \mathbf{Y}^{\parallel}_{n} = \mathbf{W}^{\parallel}_{n}\); in other words that relative information is the only information available post-sequencing. However, the values after sequencing are only estimates of the true underlying values that we want to estimate and different technical and biological replicates vary. Note that under this strong assumption no corresponding estimate or information is obtained for the scale of the sample \(\mathbf{Y}^{\perp}_{n}\). 

One issue that was realized very early was that if the goal was to compare one sample to another then the output from HTS needed to be normalized in order to make the samples commensurate and to correct any minor asymmetries in the data. A large number of normalizations were developed. Rarefaction[@Hughes:2005tu] was used in the microbiome field, while transcriptome investigators developed and used proportions and derivatives (reads per kilobase per million, and transcripts per kilobase per million[@Mortazavi:2008; @wagner:tpm]), the relative log expression (RLE)[@Anders:2010] and trimmed mean of M values (TMM)[@Robinson:2010a]. The centered log ratio (CLR)[@aitchison1982] the  approach was proposed as a unifying normalization[@fernandes:2014]. With the exception of rarefaction, all of these normalizations are ratios with the major differences between approaches being how the denominator is chosen and whether the ratio is always log transformed or not. 

For the CLR, \(\mathbf{CLR}_{dn} = mathbf{Y}_{dn} / G_n \). Recently, [@nixon2023scale] showed that certain normalizations implied that the geometric mean \(G_n\) of \(\mathbf{Y}^{\parallel}_{n}\)  was related to the scale of \( \mathbf{W} \); i.e., it was related to \(\mathbf{W}^{\perp}_n\). From an information theoretic perspective, \(G_n\) is strongly correlated with Shannon's entropy, indicating that some knowledge of the complexity of \( \mathbf{W} \) is available post-sequencing (Supplemental). Recognition of the relationship between the underlying scale \(\mathbf{W}^{\perp}_n\) and  \(G_n\) led to the realization that the relationship could introduce latent bias into analyses that has been unacknowledged. The bias occurrs because the geometric mean, or other denominator, was assumed implicitly to be a perfect point estimate of the scale of the underlying system. This suggested that adding uncertainty to the geometric mean could provide a buffer of uncertainty and acknowledge the bias introduced by normalization.

The ALDEx2 R package [@fernandes:2013] represents a general purpose toolbox for Bayesian estimation of HTS datasets. ALDEx2 was designed originally to convert point estimates of \(\mathbf{Y}^{\parallel}_{dn}\) into posterior distributions through Monte-Carlo sampling from the Dirichlet distribution; the posterior more accurately represented variation on a per-sample basis[@gloorAJS:2016]. Each Monte-Carlo replicate is normalized using the CLR and used to calculate summary and test statistics, and finally  expected values and confidence intervals are reported across the Monte-Carlo replicates. The CLR calculation uses as the denominator the geometric mean of each Monte-Carlo replicate of \(\mathbf{Y}^{\parallel}_{dn}\) with the geometric mean representing a point estimate of scale, i.e. of \(\mathbf{Y}^{\perp}_{n}\). We  now include a posterior distribution of the scale into this process by sampling \(\mathbf{Y}^{\perp}_n\) from a log-Normal distribution and using these as the denominator. The scale estimates can be calculated on a per-experiment, per-group or even a per-sample basis.

An advantage of incorporating scale is that  analyses can be made much more robust such that actual or potential differences in scale can be accounted for explicitly. The examples below show how incorporating scale provides robust and interpretable differential abundance estimates in several different datasets. 

# Results

The first dataset is a highly replicated yeast transcriptome where one condition is wild-type and the other has a snf-1 gene knockout[@Gierlinski:2015aa]. Yeast deficient for snf-1 grow more slowly and are sensitive to a variety of common agents that cause cell stress [@Yoshikawa:2011aa]. This dataset has been used to argue that only a small number of replicates need to be used to identity differentially abundant genes and that different tools should be used for datasets with different sample sizes because the tools have different intrinsic statistical power and Type 1 and Type 2 errors [@Schurch:2016aa]. This guidance runs counter to standard statistical practice where power is intrinsically linked to sample size [@Halsey:2015aa], yet the concept of sample-size independent power is entrenched in all fields that use HTS as an experimental readout. Increasing false precision with increasing sample size can be understood as the result of unacknowledged bias brought about because of false certainty as to the scale of the data. Thus, by adding scale uncertainty we can be more confident that the analysis is not converging on a precise but biased estimate of scale [@Gustafson2015].

We start by examining the dispersion or variance of the data as counts and as the logarithm of the normalized counts as calculated by DESeq2 (log(RLE)) and by ALDEx2 (CLR). The actual counts of data derived from sequencing are overdispersed with the mean value being less than the variance [@Robinson:2010] as seen in Panel A of Figure 1. This relationship is why most tools model the counts with the Negative Binomial distribution[@polyester:2016], and use this distribution as the basis for batch correction[@Zhang:2020ab]. However, the actual analysis of differential abundance is performed on the logarithm of the normalized counts [@Robinson:2010; @Love:2014aa], or on  the clr values [@fernandes:2013] both of which are log-ratios. The mean-dispersion distribution of these log-ratio transformed data is quite different as shown in panels B and C of Figure 1 and as noted elsewhere [@fernandes:2013; @Love:2014aa]. 

```{r dispersion, echo=F, warning=F, message=F,comment=F, result=F, fig.cap="Plot of abundance v dispersion for a typical transcriptome dataset as counts,  as logarithms of counts, and as clr values. Panel A shows that the data are over-dispersed relative to a Poisson distribution which is represented by the dashed line when plotted on a log-log scale. Panel B shows that the relationship between the mean and the dispersion calculated in DESeq2, here the standard error (SE) of the mean, is very different when the data are log-transformed first. Panel C shows the equivalent values calculated by ALDEx2  in which the expected clr value for each transcipt are plotted vs. the expected dispersion. The red line in each panel shows the loess line of fit to the mid-point of the distributions. In panels B and C the amount of dispersion reaches a minimum at moderate  values.  The dashed orange line in panel A is the line of equivalence, and in panel B and C is the minimum y value. The values below the dashed grey line in panels B and C represent those below the first decile of dispersion." }

library(DESeq2)
devtools::load_all('~/Documents/0_git/ALDEx_bioc')
#library(ALDEx2)

url <- "https://raw.githubusercontent.com/ggloor/datasets/main/transcriptome.tsv"
yst <- read.table(url, header=T, row.names=1)
# remove the one gene with 0 reads

yst <- yst[rownames(yst) != "YOR072W-B",]

# Gierlinski:2015aa
yst[,c('SNF2.6', 'SNF2.13','SNF2.25','SNF2.35')] <- NULL 
yst[,c('WT.21','WT.22','WT.25','WT.28','WT.34','WT.36')] <- NULL  

conds <- c(rep('S', 44), rep('W', 42))
coldata <- data.frame(conds)

# DESeq2
load('analysis/res.Rda')

#ALDEx2
load('analysis/x.all.Rda')
load('analysis/x.s.all.Rda')

# with gamma = 1
load('analysis/x.s.all.Rda')
sig.des <- which(res@listData$padj < 0.01)
sig.ald <- which(x.all$we.eBH < 0.01)
sig.s.ald <- which(x.s.all$we.eBH < 0.01)

# get and plot mean/var or mean/SE for counts
# and log counts
yst.mn <- apply(yst, 1, mean)
yst.mn.log <- apply(yst, 1, function(x) mean(log2(x)))
yst.mn.log[is.infinite(yst.mn.log)] <- 0

yst.v <- apply(yst, 1, var)

par(mfrow=c(1,3))
plot(log2(yst.mn), log2(yst.v), pch=19, cex=0.5, col=rgb(0,0,0,0.2),
  xlab='Mean count', ylab='Variance')
#points(log2(yst.mn[sig.des]), log2(yst.v[sig.des]), pch=19, cex=0.5, col='orange')
def <- data.frame(log2(yst.mn),log2(yst.v))
lines(lowess(def, f=0.1), col=2, lwd=2)
title('A: Mean vs. Variance', adj=0, line= 0.8)
abline(0,1, col=rgb(1,0.6,0,0.5), lwd=2, lty=2)

l.df <- data.frame(yst.mn.log, res@listData$lfcSE)
plot(l.df, pch=19, cex=0.5, col=rgb(0,0,0,0.2),
  xlab='Mean log2(count)', ylab='SE log2(count)',ylim=c(0,0.4))
lines(lowess(l.df, f=0.25), col=2, lwd=2)
abline(h=min(lowess(l.df)$y), col=rgb(1,0.6,0,0.5), lwd=2, lty=2)
 abline(h=0.0275, col='grey', lty=2)
title('B: log2 Mean vs. log2 Variance', adj=0, line= 0.8)

l.df <- data.frame(x.all$rab.all, x.all$diff.win)
plot(x.all$rab.all, x.all$diff.win, cex=0.5, col=rgb(0,0,0,0.2),
  xlab='E(clr)', ylab='E(dispersion)')
#points(x.all$rab.all[sig.ald], x.all$diff.win[sig.ald], col='orange', cex=0.4)
lines(lowess(l.df, f=.1), col=2, lwd=2)
abline(h=min(lowess(l.df)$y), col=rgb(1,0.6,0,0.5), lwd=2, lty=2)
 abline(h=0.208, col='grey', lty=2)
title('C: E(clr) vs. E(dispersion)', adj=0, line= 0.8)
```

Here we can see that while the variance or dispersion always increases with increasing raw read count, it actually decreases when measured on the log-ratio transformed data [@fernandes:2013; @Love:2014aa] and reaches a minimum at some mid-point of the distribution. This makes the counter-intuitive suggestion that genes with moderate expression have more predictable expression than genes with very high expression such as housekeeping genes. This is at odds with the known biology of cells where single cell counting of housekeeping transcripts shows that they are both highly expressed and have little intrinsic variation [@Taniguchi:2010aa]. Furthermore, the actual amount of dispersion is very small and for many transcripts is almost negligible. To show this point more clearly, the majority of the transcripts in the lowest decile of dispersion indicated below the dashed grey line are statistically significantly different (75% with DESeq2, 69% with ALDEx2), suggesting that low dispersion estimates lead to many false positives because of the underestimation of dispersion. The work of [@nixon2023scale] suggests that this is because the biased estimates of \(G_n\) that are  calculated leads to a false estimate of the scale. Thus, the actual variation of highly expressed genes is not captured accurately by current approaches to analysis and supports the idea that HTS have unacknowledged bias because scale is not taken into account. 

Using either DESeq2 or ALDEx2, we observe that a majority of transcripts are statistically significantly different between groups even with a Benjamini-Hochberg [@benjamini:1995] false discovery rate (FDR) of 0.01; i.e. `r length(sig.des)` or `r length(sig.ald)` of the `r nrow(yst)` transcripts are statistically significant. Clearly, the necessary assumption of most features being invariant is not justified. Applying the rule of thumb of at least a $2^{1.4}$ fold change [@Schurch:2016aa] reduces these outputs to `r length(which(res@listData$padj < 0.01 & abs(res@listData$log2FoldChange) > 1.4))` for DESeq2 and to `r length(which(x.all$we.eBH < 0.01 & abs(x.all$diff.btw) > 1.4))` for ALDEx2. 

```{r plot1, echo=F, fig.cap="Effect and volcano plots for unscaled and scaled transcriptome analysis. DESeq2 or ALDEx2 were used to conduct a differential abundance (DA) analysis on the yeast transcriptome dataset. The results were plotted to show the relationship between difference and dispersion (effect plot [@gloor:effect]) or difference and the Benjamini-Hochberg corrected p-values (volcano plot[@Cui:2003aa]). Panels A,B,D,E are for the unscaled analysis, and Panels C,F are for the scaled analysis. Each point represents the values for one transcript, with the color indicating if that transcript was significant in the scaled analysis and unscaled analysis (red) or in the unscaled analysis only (orange). Points in grey are not statistically signficantly different with any analysis. The horizontal dashed lines represent a log2(difference) of 1.4, which is a commonly applied cutoff when the majority of features are statistically significant."}
par(mfrow=c(2,3))
plot(res@listData$lfcSE*sqrt(ncol(yst)), res@listData$log2FoldChange, xlim=c(0,5), 
  col=rgb(0,0,0,0.1), xlab='LFC SD', ylab='log2 Difference')
title('A: DESeq2 effect', adj=0, line= 0.8)
points(res@listData$lfcSE[sig.des]*sqrt(ncol(yst)),
  res@listData$log2FoldChange[sig.des], col=rgb(1,.66,0,0.5), 
  pch=19, cex=0.5)
points(res@listData$lfcSE[sig.s.ald]*sqrt(ncol(yst)),
  res@listData$log2FoldChange[sig.s.ald], col=rgb(1,0,0,0.5), 
  pch=19, cex=0.5)
abline(h=c(-1.4,1.4), lty=2, col='grey')

plot(x.all$diff.win, x.all$diff.btw, col=rgb(0,0,0,0.1), 
   xlab='Dispersion', ylab='log2 Difference')
title('B: ALDEx2 effect', adj=0, line= 0.8)
points(x.all$diff.win[sig.ald], x.all$diff.btw[sig.ald], 
  col=rgb(1,.66,0,0.3), cex=0.5, pch=19)
    abline(h=c(-1.4,1.4), lty=2, col='grey')
points(x.all$diff.win[sig.s.ald], x.all$diff.btw[sig.s.ald], 
  col=rgb(1,0,0,0.6), cex=0.5, pch=19)
    abline(h=c(-1.4,1.4), lty=2, col='grey')

plot(x.s.all$diff.win, x.s.all$diff.btw, col=rgb(0,0,0,0.1),
   xlab='Dispersion', ylab='log2 Difference', xlim=c(0.1,5))
title('C: ALDEx2 scaled effect', adj=0, line= 0.8)
points(x.s.all$diff.win[sig.s.ald], x.s.all$diff.btw[sig.s.ald], 
  col=rgb(1,0,0,0.5), cex=0.5, pch=19)
    abline(h=c(-1.4,1.4), lty=2, col='grey')

# volcano
plot(res@listData$log2FoldChange,-1*log10(res@listData$padj + 1e-300), 
  col=rgb(0,0,0,0.1), xlab='log2 Difference', ylab='-1 log10(p.adjust)')
title('D: DESeq2 volcano', adj=0, line= 0.8)
points(res@listData$log2FoldChange[sig.des],-1*log10(res@listData$padj[sig.des] + 1e-300), col=rgb(1,.66,0,0.3), 
  pch=19, cex=0.5)
points(res@listData$log2FoldChange[sig.s.ald],-1*log10(res@listData$padj[sig.s.ald] + 1e-300), col=rgb(1,0,0,1), 
  pch=19, cex=0.5)
  abline(v=c(-1.4,1.4), lty=2, col='grey')

plot(x.all$diff.btw, -1*log10(x.all$we.eBH +1e-70), col=rgb(0,0,0,0.1), 
   xlab='log2 Difference', ylab='-1 log10(p.adjust)')
title('E: ALDEx2 volcano', adj=0, line= 0.8)
points(x.all$diff.btw[sig.ald], -1*log10(x.all$we.eBH[sig.ald]  +1e-70), 
  col=rgb(1,.66,0,.3), cex=0.5, pch=19)
points(x.all$diff.btw[sig.s.ald], -1*log10(x.all$we.eBH[sig.s.ald]  +1e-70), 
  col=rgb(1,0,0,1), cex=0.5, pch=19)
abline(v=c(-1.4,1.4), lty=2, col='grey')


plot(x.s.all$diff.btw, -1*log10(x.s.all$we.eBH +1e-15), col=rgb(0,0,0,0.1),
   xlab='log2 Difference', ylab='-1 log10(p.adjust)')
title('F: ALDEx2 scaled volcano', adj=0, line= 0.8)

points(x.s.all$diff.btw[sig.s.ald], -1*log10(x.s.all$we.eBH[sig.s.ald]+1e-15),
  col=rgb(1,0,0,1), cex=0.5, pch=19)
    abline(v=c(-1.4,1.4), lty=2, col='grey')

```

As shown in Figure 2 A,B,D,E the root cause of the many statistically significant positive transcripts is the very large number of transcripts with negligible variance with both DESeq2 and ALDEx2. We can see that almost all the transcripts that are differentially abundant with an FDR < 0.01 (orange and red points) have extremely low dispersion and a very low difference between groups. In the most extreme cases transcripts with near 0 difference have a low FDR. This issue lead to the common practice of choosing transcripts with a low FDR and a fold-change threshold [@Schurch:2016aa] (commonly set at $\pm 2^{1.4}$), and these limits are shown by the dashed grey lines. A similar sitation arises when using the ALDEx2 package, and indeed the two methods identify substantially similar transcripts. This results begs the question, "why bother with the signficance test?". [XXXX CHECK THE DIRECTION OF SCALE IN THIS DATASET]

The very low dispersion estimate for most of the features  arises because  scale variation in the underlying data has been removed through sequencing and normalization. While the actual scale of the data is inaccessible post-sequencing  we can estimate the \emph{effect of scale on the output. To do this, we add uncertainty to the denominator that is used to calculate the log-ratio of the samples [@nixon2023scale], and combine this with the posterior probabilities that ALDEx2 calculates on a per-feature basis [@fernandes:2013]. Scale uncertainty is incorporated using the `gamma` parameter that controls the amount uncertainty being included when we call either `aldex()`, or `aldex.clr()`. The `ALDEx2` package further contains a sensitivity analysis function, `aldex.senAnalysis()`, that can be used to explore the effect of different amounts of scale uncertainty. In practice we suggest that a `gamma` parameter between 0.5 and 1 is realistic for most experimental designs.

Applying `gamma=1` as a parameter we can see that the large number of transcripts with near 0 dispersion have had their dispersion increased (Figure 2C), and this results in many fewer transcripts (`r length(sig.s.ald)`) being called significantly different  as shown in the volcano plot in Figure 1F (red points). Furthermore, overplotting the significant transcripts identified after adding scale uncertainty on the un-scaled analysis shows that adding scale uncertainty removes the need for the dual cutoff.  Indeed, adding scale uncertainty reduces the significant transcripts to approximately the number observed with the somewhat arbitrary difference cutoff. Thus, incorporating scale uncertainty through the default scale model allows us to determine which variables are likely to be significant due to sequencing and normalization, and which are significantly different even with scale uncertainty included.
  

The second example dataset is a vaginal metatranscriptome dataset used in [@Macklaim:2018aa,@Wu2021], where we are comparing gene expression in bacteria collected from healthy (H) and BV-affected women.  In this environment, both the relative abundance of species between groups is different as is the gene expression levels within a species [@macklaim:2013]. We further know that the total number of bacteria is about 10X more in BV than in H [@Zozaya:2010]. Thus, this is  an extremely challenging environment in which to determine differential abundance. Indeed, the accepted method to analyze vaginal metatranscriptomes is to conduct a taxon by taxon analysis rather than a system-wide analysis [@macklaim:2013;@Denge00262-18;@Fettweis:2019aa] because a pooled analysis unexpectedly identifies many housekeeping genes as being differentially abundant between groups. 

In this example we show how to specify the scale model explicitly and demonstrate that applying different scale models to each group independently can control for the very large difference in scale in the underlying data. When specifying the whole scale model we can pass a matrix of scale values instead of a single to `aldex.clr()`. This matrix should have the same number of rows as the of Monte-Carlo Dirichlet samples, and the same number of columns as the number of samples. 

This scale model matrix encapsulates two aspects of scale uncertainty and explicitly illustrates the concept of . First, as in the example above, gamma indicates the uncertainty of the de of the scale model on a per-sample basis.

Figure 3A shows an effect plot [@gloor:effect] of the data where reads are grouped by function, corresponding approximately to grouping orthologous sequences regardless of the organism of origin. Each point represents one of the 3728 functions, and we can see that there are many more functions represented in the BV group (bottom) than in the healthy group (top). This is because the \textit{Lactobacilli} that dominate a healthy vaginal microbiome have reduced genome content relative to the anaerobic organisms that dominate in BV, because  there is a greater diversity of organisms in BV than in H samples and because the BV condition has at least an order of magnitude more bacteria than does the H condition. 

 We can  see that there are a large number of functions that are shared between the two groups (boxed area in Figure 3A), and inspection shows that these largely correspond to core metabolic functions that would not be expected  to contribute to differences in ecosystem behaviour. As a proxy for housekeeping functions the core ribosome functions (blue) shows that their mean location is not centred on 0. The major group of these housekeeping functions is located off the line of no difference (being approximately located at +1.5) and not surprisingly have among the lowest dispersion in the dataset. Nevertheless, they are identified as differentially abundant (red) along with many others. While changes in the abundance of housekeeping functions is a useful proxy for relative abundance of species in the environment, they tell us nothing about the functional capacity of the two groups because these are functions in common to every organism. Of more interest is determining the functions that are different between groups because these are unique or over-expressed in one group relative to the other.  


```{r ribo, echo=F}
ribo.v <- c("K02863","K02864","K02865","K02866","K02867","K02871","K02872","K02873","K02874","K02876","K02877","K02878","K02879","K02880","K02881","K02883","K02884","K02885","K02886","K02887","K02888","K02890","K02892","K02895","K02897","K02899","K02902","K02904","K02905","K02906","K02907","K02909","K02911","K02913","K02914","K02916","K02920","K02922","K02926","K02931","K02932","K02933","K02935","K02936","K02938","K02939","K02941","K02943","K02945","K02946","K02948","K02949","K02950","K02952","K02954","K02955","K02956","K02959","K02961","K02963","K02964","K02965","K02967","K02968","K02969","K02970","K02975","K02981","K02982","K02984","K02986","K02987","K02988","K02990","K02991","K02992","K02994","K02995","K02996","K02997","K02998","K07590")
```


```{r meta, echo=F, warning=F, message=F,comment=F, result=F, fig.cap="Analysis of vaginal transcriptome data aggregated at the Kegg Orthology (KO) functional level. Panel A shows the default analysis with samples from healthy individuals at the top and from BV individuals at the bottom. Highlighed in the box are highly abundant KOs that are almost exlusively housekeeping functions, with ribosomal KOs highlighted in blue,  statistically significant (FDR < 0.01) functions in red, and non-significant functions in black or orange. These housekeeping functions are off the midline of no difference. Panel B shows the same data scaled with `gamma = 1`, which increase the minimum dispersion approximatly by one unit. Here the housekeeping functions from Panel A are colored cyan or blue for reference. Panel C shows the same data scaled with `gamma = 0.75` and a 0.15 fold difference in dispersion applied to the BV samples relative to the H samples. The orange functions are now statistically significant. Note that this shifts the midpoint of the housekeeping functions towards the midline." }

# all code for ALDEx2 and DESeq is being moved to the code/directory
# all variables recreated using the makefile

load('analysis/xt.Rda')
load('analysis/xg.Rda')
load('analysis/xt.m.Rda')

hk <- rownames(xt.all)[xt.all$diff.win < 2.5 & xt.all$diff.btw > 0 & xt.all$diff.btw < 3]
hk.off <- xt.all$diff.win < 2.5 & xt.all$diff.btw > 0 & xt.all$diff.btw < 3

fn <- rownames(xt.m.all)[xt.m.all$we.eBH < 0.01 & xt.m.all$diff.btw < 1 & xg.all$we.eBH > 0.01 & xt.all$we.eBH > 0.01]

#par(mfrow=c(1,1))
#plot(density(xt.m.e$diff.btw[hk.off]))
#abline(v=0, col='red')

par(mfrow=c(1,3))
aldex.plot(xt.all, cutoff.pval=0.01)
points(xt.all[ribo.v,'diff.win'], xt.all[ribo.v,'diff.btw'], col='blue', cex=0.5, pch=19)
points(xt.all[fn,'diff.win'], xt.all[fn,'diff.btw'], col='orange', cex=0.5, pch=19)
rect(0.5,0,3,5, col=rgb(0,0,0,0.1), lty=2, lwd=3)
title('A: ALDEx2 unscaled', adj=0, line= 0.8)

aldex.plot(xg.all, xlim=c(0.3,9), cutoff.pval=0.01)
points(xg.all$diff.win[hk.off], xg.all$diff.btw[hk.off], pch=19, cex=0.4, col=rgb(0,1,1,0.5))
points(xg.all[ribo.v,'diff.win'], xg.all[ribo.v,'diff.btw'], col='blue', cex=0.5, pch=19)
points(xg.all[fn,'diff.win'], xg.all[fn,'diff.btw'], col='orange', cex=0.5, pch=19)
title('B: ALDEx2 gamma scaled', adj=0, line= 0.8)


aldex.plot(xt.m.all, xlim=c(0.3,9), cutoff.pval=0.01)
points(xt.m.all$diff.win[hk.off], xt.m.all$diff.btw[hk.off], pch=19, cex=0.4, col=rgb(0,1,1,0.5))
points(xt.m.all[ribo.v,'diff.win'], xt.m.all[ribo.v,'diff.btw'], col='blue', cex=0.5, pch=19)
points(xt.m.all[fn,'diff.win'], xt.m.all[fn,'diff.btw'], col='orange', cex=0.5, pch=19)
title('C: ALDEx2 both scaled', adj=0, line= 0.8)


```

Applying the default scale model of `gamma=1` as before increases the dispersion as expected, but does little to move the large number of housekeeping functions toward the midline of no difference. Nevertheless, about 50% of the housekeeping functions are no longer statistically significantly different. 

Up to this point, scale uncertainty has been applied uniformly to both conditions, but a user-defined scale adjustment can be applied to each condition, or even each sample independently through a custom scale matrix. For this we need to revisit the concept that all normalizations in widespread use are actually ratios with the denominator chosen by one of several methods. It is important to recognize that in some datasets the denominator itself is not crucial as all approaches give substantially similar results; the transcriptome example above is a good example of such an idealized dataset. This begs the question, "if it is not the denominator, what then is the important determinant?" As shown by [@nixon2023scale] it is the \emph{relationship} between the scale values that is important, not their actual value and this can be illustrated quite simply by starting with the mean ratio in \( G\) between groups for the yeast transcriptome dataset which are  \(6.05\times^{-5}\) for snf-w and \(5.08\times^{-5}\); their ratio being 1.17, or a 0.17-fold difference. Using this information, we can recapitulate the differential abundance analysis in Figure 2B and 2C exactly by using setting the mean denominator of group 1 to 1, and group 2 to 1.17 (supplemental). Altering this ratio moves the location of the data.

With this background, we can understand how to apply a full scale to the metatranscriptome dataset   with the `aldex.makeScaleMatrix()` function. The full scale model option can be used ot make a matrix of relative scales that are distinct for each group (or even each sample) along with their uncertainties. Applying a per-group relative differential scale of 0.15 with a base scale of 1 moves the housekeeping functions to the midline of no difference (Figure 3C).  Note that now a significant number of functions  are differentially up in BV that were formerly classed as not different without scale, or when only a uniform  scale was applied. These former false negatives are noted in orange in each panel. Inspection of the functions shows that these are largely missing from the Lactobacillus species and so should actually be captured as differentially abundant. Thus, applying differential scale allows us to distinguish between both false positives (housekeeping functions in cyan) and false negatives (orange functions) even in a very difficult to analyze dataset. We suggest that the default scale model alone is useful and should be normally applied when the data are well centred. However, when datasets are not well centred or when the investigator has prior information about the underlying biology, we advocate developing and using a full differential scale model.

# Discussion

Biological count data can be decomposed into two parts the relative (compositional) and the absolute (scale), and the product of these generates a fully scaled biological system [@nixon2023scale]. Biological systems are both predictably variable and stochastic and current measurement methods that rely on high throughput sequencing fail to capture all of that variation. In the absence of  information external to the sequencing run itself, no normalisation method can recapture any of the scale information [@Loven:2012aa]. 

Since the underlying scale of the system cannot be measured easily -- methods such as flow cytometry [@Vandeputte:2017aa], spike-in probes and fluorescent in-situ hybridization [@Loven:2012aa;@yeast-absolute] have been used -- the effect on analysis can be modelled by including scale uncertainty in the analysis [@nixon2023scale]. Nixon et al, showed that this can be done by including uncertainty in the denominator used for the normalization. The ALDEx2 R package is ideally suited for this since this tool builds a Bayesian posterior of the compositional component of the dataset at the outset and then conducts the analysis on that posterior. Adding scale uncertainty can be done at the same time thus producing a posterior model that incorporates both compositional and scale uncertainty. For this, the compositional uncertainty is sampled from a Dirichlet distribution, and the scale uncertainty is sampled from a log-Normal distribution.

All normalizations attempt to make the samples in a dataset commensurate but do not explicitly address the scale of the underlying system. However, the general lack of scale information has important consequences for the analysis of HTS datasets. One issue is that analysis tools  seem over-powered with even moderate sample sizes and different tools have different intrinsic power, Type 1 and Type 2 error rates  [@Schurch:2016aa]. Using small sample sizes in analysis leads to less reliability and reproducibility in analyses since surprisingly large sample sizes are needed to determine reproducible p-values (eg. [@Halsey:2015aa]). Thus, recommendations to use small sample sizes in multivariate datasets such as RNA-seq datasets are not supported by simple modelling in the univariate case. Another issue is that datasets are difficult to analyze when there they contain systematic asymmetry, with different tools exhibiting differing pathologies with these datasets [@Robinson:2010a, @Wu2021].

In the case of overpowering, HTS analyses seem to be more robust when applying a dual cutoff of both p-value and difference between group means [@Schurch:2016aa]. Figure 2 shows one reason for this robustness could be that the dual cutoff is mimicking the effect of including scale uncertainty, since substantially similar transcripts are identified by the two approaches. However, while using the post-hoc difference cutoff is useful for differential abundance analysis it is not clear how this can be incorporated into other kinds of downstream analyses. Conversely analyses that include scale uncertainty are fully compatible with existing downstream analyses.

In the case of asymmetry, the use of a user-specified scale model can be very useful for otherwise difficult to analyze datasets such as meta-transcriptomes and in-vitro selection datasets where the majority of features can change. We showed one such example in Figure 3 where the dataset was highly asymmetrical, and the TMM and RLE normalizations cannot fully move all the housekeeping genes to the midline of no difference or exhibit other pathologies (supplemental). Incorporating differential scale on a per-group basis moves the mass of the data towards the midline of no difference and so affects both Type I and Type II error rates. In this analysis, transcripts that were previously not classed as differentially abundant are now called as significantly different, and the housekeeping transcripts move from being significantly different to not being identified as such. While we acknowledge that some prior information on which housekeeping transcripts should not be classed as DA is needed, we suggest that this information is widely available and is already used when performing the gold-standard quantitative PCR test of differential abundance [@Thellin:1999aa,@SEQC/MAQC-III-Consortium:2014aa]. Furthermore, the assumption that housekeeping genes should not generally be included in differential abundance analysis is implicit in the dual p-value, fold-change cutoff approach in widespread use. Thus, the use of this prior knowledge is not unique to our approach.

In summary, while the underlying scale of the system is generally inaccessible, the effect of scale on the analysis outcomes can be modelled and can help explain some of the underlying biology. Adding scale information to the analysis allows for more robust inference because the features that are sensitive to scale can be identified and their impact on the analysis weighted accordingly. Additionally, the use of differential scale models permits difficult to analyze datasets to be examined in a robust and principled manner even when the majority of features are asymmetrically distributed or expressed (or both) in the groups. Thus, reporting scale uncertainty should become a standard practice in the analysis of HTS datasets as a way to identify which features are most robust to differences in the underlying system. Finally, we supply a toolkit that makes incorporating scale simple even for datasets that come from highly asymmetrical environments. 



