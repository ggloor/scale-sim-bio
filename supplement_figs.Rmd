---
title: "Supplement: Beyond compositionally in high throughput sequencing; estimating the importance of scale in data analysis with ALDEx2
"
shorttitle: "Scale ALDEx2 Supp"
author:
- name: Greg Gloor, Michelle Pistner Nixon, Justin Silverman
  affiliation: Dep't of Biochemistry, University of Western Ontario, Penn State
  email: ggloor@uwo.ca
bibliography: /Users/ggloor/Library/texmf/bibtex/bib/bibdesk_refs.bib
output:
  BiocStyle::pdf_document: default
package: ALDEx2 1.33.1
abstract: |
    Introduction to scale simulation and FDR correction with ALDEx2.
date: 21 August 2023
link-citations: true
---

# GM is related to Information and Shannon's entropy in HTS datasets

Information content is a fundamental property of all systems. We can think about  scale  from an information theoretic point of view as a measure of how much information is encoded in a particular sample. Intuitively,   systems with different scales will contain different amounts of information and so we would expect \(W^{\perp}_n \sim H_n\). Below, we show that the scale of a system as defined by Nixon et al. [-@nixon2023scale] is inversely related to the information content and entropy of the data. 

Recall the underlying system is described by a \(D \times N\) matrix of counts \(\mathbf{W}\) decomposed into the proportions for the \(n^{th}\) sample \(\mathbf{W}^{\parallel}_n\) (or the equivalent probability distribution \( \mathbf{p}(w_n) \) ), and its scale \(\mathbf{W}^{\perp}_n\), such that \(\mathbf{W}=\mathbf{W}^{\parallel}\mathbf{W}^{\perp} \). Sequencing  returns counts which are related to the underlying proportion; i.e., \(\mathbf{Y}^{\parallel}_n \sim \mathbf{W}^{\parallel}_n\)
 

For notational simplicity assume we will use a single discrete random variable to represent the probability distribution; i.e. \( X =  \mathbf{p}(w_n) \)  over \(1 \dots d \) elements. The geometric mean can be calculated as: 

\[
\log_2 G(X) = \frac{1}{d} \sum_{i=1}^{d} \log_2 p_i
\];

here every element in \(log_2 G(X)\) is the logarithm of the elemental probability \( log_2(p_i)\). 

In information theory, the elemental amount of information or uncertainty for \(p_i\) is the inverse \(I(X)_i = -log_2(p_i)\)[@rezaInfoIntro]. 

The total entropy of the system  \( H(x) \) is the weighted sum of the elemental information

\[
H(x) = -\sum_{i=1}^{d} p_i \log_2 p_i
\]

In this formulation, \( \log_2(G(X)) \) and \( H(X) \) can be understood  to be an unweighted and a weighted measure  of 'surprisal' in the dataset.  The total and the mean surprisal are related by the number of terms in \( p(x) \) and by the weighting factor for each term. \( H(X) \) corresponds to the amount of information needed in order to reproduce  \( X \). Conversely, \( G \) is an unweighted mean of the same distribution and  \( G \) is the denominator to calculate the centred log-ratio normalization (CLR). Note that when calculating the CLR we are taking a ratio, and similarly for calculating entropy, but that the scale formula takes the product. Thus, the scale of a system is inversely related to the other two measures.

Empirically, we can see that \(G(\mathbf{Y}^{\parallel}_{n})\) is strongly correlated with Shannon's Entropy \(H(\mathbf{Y}^{\parallel}_{n})\) (Supplemental Figure 1 and Table 1).  These two measures are expected to have different behaviours with different distributions of \( p_i \). In the case of a uniform distribution both \( H(\mathbf{Y}^{\parallel}_{n}) \) and \( G(\mathbf{Y}^{\parallel}_{n}) \) are maximal since \( p(x) \) is equally and identically distributed. Thus, we expect that they are positively correlated here. In a Normal or a skewed distribution, we also anticipate a positive correlation because both are affected in the same direction by outlier values. In very sparse  datasets, the two measures could become uncoupled because \( H(\mathbf{Y}^{\parallel}_{n}) \) could ascribe some uncertainty to the large number of low probability events, while \( G(\mathbf{Y}^{\parallel}_{n}) \) would tend to be very small. Here these two measures could be either uncorrelated or exhibit negative correlation. We can see this distributional behaviour in different datasets.


```{r info, echo=F,warning=F, message=F,comment=F, fig.cap="Plot of Shannon's entropy (H) vs geometric mean (G) for each sample in different datasets. The groups that each sample belong to are highlighted as filled or open circles. Each group in each dataset has different entropy with the groups in the selex and metatranscriptome datasets being highly distinct."}
# Gm ~ Im
# plotting geometric mean vs Shannon's entropy
# shows differential information by group
devtools::load_all('~/Documents/0_git/ALDEx_bioc')
data(selex)

load(url('https://raw.githubusercontent.com/ggloor/datasets/main/ko.both.Rda'))
url <- "https://raw.githubusercontent.com/ggloor/datasets/main/transcriptome.tsv"
yst <- read.table(url, header=T, row.names=1)
url <- "https://raw.githubusercontent.com/ggloor/datasets/main/meta16S.tsv"
rRNA <- read.table(url, header=T, row.names=1, sep='\t')
url <- "https://raw.githubusercontent.com/ggloor/datasets/main/singleCell.tsv"
ss <- read.table(url, header=T, row.names=1, sep='\t')
ss <- ss[,c(1:100,1502:1601)]
# remove the one gene with 0 reads
yst <- yst[rownames(yst) != "YOR072W-B",]
# Gierlinski:2015aa
yst[,c('SNF2.6', 'SNF2.13','SNF2.25','SNF2.35')] <- NULL 
yst[,c('WT.21','WT.22','WT.25','WT.28','WT.34','WT.36')] <- NULL  

HS <- apply(selex+0.5, 2, function(x) {-1 * sum( (x/sum(x)) * log2( (x/sum(x)) ) ) })
GS <- apply(selex+0.5, 2, function(x) mean(log2(x/sum(x))))

HY <- apply(yst+0.5, 2, function(x) {-1 * sum( (x/sum(x)) * log2( (x/sum(x)) ) ) })
GY <- apply(yst+0.5, 2, function(x) mean(log2(x/sum(x))))

HM <- apply(ko.both+0.5, 2, function(x) {-1 * sum( (x/sum(x)) * log2( (x/sum(x)) ) ) })
GM <- apply(ko.both+0.5, 2, function(x) mean(log2(x/sum(x))))

H16 <- apply(rRNA+0.5, 2, function(x) {-1 * sum( (x/sum(x)) * log2( (x/sum(x)) ) ) })
G16 <- apply(rRNA+0.5, 2, function(x) mean(log2(x/sum(x))))

Hss <- apply(ss+0.1, 2, function(x) {-1 * sum( (x/sum(x)) * log2( (x/sum(x)) ) ) })
Gss <- apply(ss+0.1, 2, function(x) mean(log2(x/sum(x))))

par(mfrow=c(2,3))
plot(HS, GS, ylab="Geometric mean", xlab="Shannon's entropy",
  pch=c(rep(19,7),rep(1,7)), col=rgb(0,0,0,0.5))
title(main='selex')

plot(HY,GY, 
  ylab="Geometric mean", xlab="Shannon's entropy", pch=c(rep(19,44),rep(1,42)),
  col=rgb(1,0.6,0,0.5))
title(main='transcriptome')

plot(HM, GM, col=rgb(1,0,0,0.5), pch=c(rep(1,8), rep(19,28), rep(1,8)), 
  ylab="Geometric mean", xlab="Shannon's entropy")
title(main='meta-transcriptome')

plot(H16,G16, col=rgb(0,1,1,0.5),
  pch=c(rep(1,198), rep(19,161)), 
  ylab="Geometric mean", xlab="Shannon's entropy")
title(main='16S rRNA')

plot(Hss,Gss, col=rgb(0.5,1,0,0.5),
 pch=c(rep(1,100), rep(19,100)), 
  ylab="Geometric mean", xlab="Shannon's entropy")
title(main="single cell")

# empty plot for legend
plot(selex[,1], selex[,2], xlab=NA, ylab=NA, axes=F,xlim=c(-10,-1), ylim=c(-10,-1))
legend(-10,-1, legend=c('selex', 'transcriptome','metatranscriptome', '16S', 'SS', 'low entropy group', 'high entropy group'),
  col=c('darkgrey', 'orange', 'red', 'cyan', 'greenyellow','grey','grey'), pch=c(19,19,19,19,19,1,19))
  
```

The table below summarizes the mean values for, and the correlation between, \( G \) and \( H \)  (cor)  and the sparsity defined as the proportion of features with less than 1 count per sample (spar) for each association in each group of samples:

| Dataset | group | \(\overline{G}\) | \( \overline{H} \) | cor | spar |
|---------|-------|---|---|-----|-------|
| Selex   | control | -11.2 | 10.2 | 0.99 | 0 |
| $~~~$"  | selected | -17.8 | 2.8 | -0.88 | 0.802 |
| yeast   | snf2 ko  | -14.0 | 10.7 | 0.99 | 0.004 |
| $~~~$"  | WT    | -14.2 | 10.4 | 0.99 | 0.007 |
| Meta    | H     | -18.8 | 8.6 | 0.78 | 0.451 |
| $~~~$"  | BV   | -18.2 | 8.9 | 0.79 | 0.238 |
| 16S     | Pup   | -14.7 | 5.4 | 0.68 | 0.079 |
| $~~~$"  | Cent | -15.2 | 5.4 | 0.53 | 0.251 |
| SS      | A     | -13.0 | 8.2 | 0.83 | 0.978 |
| $~~~$"  | B    | -12.9 | 8.3 | 0.80 | 0.977 |

We can see that for most datasets the difference between the \(\overline{G}\) in each group is relatively small. Most significantly, the selex dataset has a very large difference of about 100-fold, and both the 16S and the metatranscriptome dataset have about a 1.5 fold difference. These three datasets are candidates for a full scale model correction.

```{r full.scale, echo=F, fig.cap="Plot of the offset of the mean differnece between groups as a function of scale ratio. For this, the default scale of 1:1 was altered in increments of 0.1 keeping the gamma parameter (dispersion) at 0.5. The filled circle shows the outcome when the calculation is done using the geometric mean and the same gamma parameter."}

load('analysis/data.out.Rda' )

plot(data.out[,6],data.out[,1], pch=c(rep(1,19),19), ylim=c(-11, 4),
  xlab='full scale offset', ylab='mean difference between groups')
points(data.out[,6],data.out[,2], pch=c(rep(1,19),19), col='red')
points(data.out[,6],data.out[,3], pch=c(rep(1,19),19), col='orange')
points(data.out[,6],data.out[,4], pch=c(rep(1,19),19), col='cyan')
points(data.out[,6],data.out[,5], pch=c(rep(1,19),19), col='blue')
abline(h=0, col='grey', lty=2)
abline(v=0, col='grey', lty=2)
legend(0.7, 0, legend=c('16S','selex','tscome','metatscome','ss'),
  pch=19, col=c('black','red','orange','cyan','blue'))

```

Nixon et al. [-@nixon2023scale] showed that many operations on HTS datasets relied on both the proportion and scale components of the data. Moreover, all normalizations impose a scale model on the data, but the appropriateness of these models has never been explicitly acknowledged or tested. Thus, the full scale model option allows the investigator to set both the offset between the geometric means of the features and their dispersion and observe how this affects the analysis outcome. 

In the offset plot above we can see the cause and the effect of the full model with a fixed gamma of 0.5 and a base scale of 1 in each group. We see that the mean location of well centred datasets (yeast transcriptome, single-cell transcriptome) are close to 0, but could be centred better with small changes in scale ranging from 0 (single cell) to 1:1.1 for the yeast transcriptome dataset. In contrast, centring the 16S dataset requires about a 1:1.3 fold change. The metatranscriptome dataset would require about a 0.5:1 change in relative scale between groups, but as shown in the main text, centring the housekeeping genes is more apt. 

The in vitro selection dataset is clearly an outlier in both the difference between the average group geometric mean, and in the offset plot.  However, this dataset can  be used to illustrate the power of the full scale model and the relationship between \( G_n \) and scale. In Figure 3 we can see that the default output of ALDEx2 has a centered output. This occurs largely by chance, as the high sparsity of the selected (S) group is balanced almost exactly by the arbitrarily chosen sequencing depth so the non-selected group (NS) appears to have a similar location as the S group. The difference in entropy between the two groups and the differences in geometric mean are very large, with the difference in \(\log_2{\overline{G}(S)}\) and \(log_2{\overline{G}(NS)}\) being about \(2^{6.6}\). Setting the scale of both the S and NS groups to 1 we find that the difference in location is approximately \(2^{7.7}\) in close agreement with the difference the geometric means. For this dataset to be centered we need to have a scale ratio \( \approx \) 1:50 or more. Note that the scale ratio is inverse to the ratio of geometric means as described above.  In fact, in this dataset the relative abundances of the majority of features are nearly invariant, but this is masked by the large absolute changes in a small number of features [@mcmurrough:2014], thus changing the scale of the data. Neither DESeq nor edgeR are able to provide a reasonable analysis of this dataset because the normalizations used assume equivalent scales [@gloorAJS:2016]. 

Figure 3 shows an effect plot of various scale models with this dataset. The full scale model, where the strong assumption that the mean \(G\) is assumed to be 1:1 between the two groups, dramatically skews the output and the large number of relatively invariant features are now identified as significantly different. While not wrong as long as the assumption that the scales are identical is stated, this is not a useful analysis outcome. Modifying the mean scale difference between the NS:S groups to be \( \approx \) 1:50 different moves the centre of the large number of relatively invariant features to the centreline of no difference, and recapitulates the default result obtained using \(G_n\) as the scale estimate where the ratio is \( \sim 100:1 \). Note that we get exactly the same answer (within random sampling error) with a scale of .02 for group NS and a scale of 1 for group S, or using a scale of 1 for group NS and a scale of 50 for group S. This shows that it is the relative difference between scales that is important in this dataset, not the absolute values. From this result we can conclude that, on average, the difference in underlying scale in the system is about \(\approx 50\)-fold, and this is congruent with the circa 100-fold difference in  \(\overline{G}\) between groups; the discrepancy being explained because the default scale model is applied uniformly to all samples, whereas the different values of the within-group geometric means ranging over a \{ > 2.5 \) fold range.  Thus, an advantage of a full scale model is that we have gained both information and understanding about the drivers of asymmetry underlying system.


```{r selex, echo=F, warning=F, message=F,comment=F, fig.cap="Effect plots of the selex dataset with various gamma and scale parameters. All scales are calculated with a logNormal distribution to ensure symmetry for the user. "}

conds <- c(rep('NS',7), rep('S',7))

x.all <- aldex(selex, conditions=conds, CI=T, gamma=0.5)

sel.mu <- aldex.makeScaleMatrix(gamma=0.5, mu=c(10,10), conds)
x.1.all <- aldex(selex, conditions=conds, CI=T, gamma=sel.mu)

# setting ratio as 1:50 explicitly
#sel.mu <- aldex.makeScaleMatrix(gamma=0.5, mu=c(1,50), conds, log=FALSE)
scale <- c(rep(1,7), rep(50,7)) 
sel.mu <- aldex.makeScaleMatrix(gamma=0.5, mu=scale, conds, log=FALSE)
x.5.all <- aldex(selex, conditions=conds, CI=T, gamma=sel.mu)

# setting ratio in log space
# 2^-5.64 : 2^0  = 0.02 : 1
# this also works, but reversed because of factor()  
# sel.mu <- aldex.makeScaleMatrix(gamma=0.5, mu=c(0,-5.64), conds, log=TRUE)
scale <- c(rep(-5.6,7), rep(0,7))
sel.mu <- aldex.makeScaleMatrix(gamma=0.5, mu=scale, conds, log=TRUE)

x.2.all <- aldex(selex,conditions=conds, CI=T, gamma=sel.mu)

par(mfrow=c(1,4))
aldex.plot(x.all, main=('gamma=0.5\nmu=G'))
aldex.plot(x.1.all, main=('gamma=0.5\nmu=1,1'))
aldex.plot(x.5.all, main=('gamma=0.5\nmu=1,50'))
aldex.plot(x.2.all, main=('gamma=0.5\nmu=0.02, 1'))
```

# Issues with DESeq2 and edgeR

DESeq2 and edgeR are two of the most commonly used tools for differential abundance analysis of bule RNA sequencing datasets. They both operate by finding a scaling factor that makes all the samples commesurate. DESeq2 does this by finding a midpoint feature that can be used as a reference in each sample; this can be different for different samples. The edgeR reference finds the midpoint of the 'typical' sample instead. In both cases the data are then scaled by dividing by a small factor that makes the read counts commesurate. Differential abundance analysis is then performed on the scaled values after taking their logarithm to base 2. In some ways this is similar to the log-ratio approach used by ALDEx2, but is more prone to dataset and sample effects than is the log-ratio method [@GloorAJS2023] 

```{r DESedg, echo=F, fig.cap="Shown here are the mean log2 fold change as a density plot, and a Volcano plot showing the location and adjusted p-value for each feature in the metatranscriptomic dataset. The DESeq2 approach does a good job of centring this data, while edgeR is less suitable. The volcano plots show dramatically different outcomes. The DESeq2 algorithm assigns very large fold changes to features that have only moderate change, and further identifies a very large proportion of features as significantly different. In contrast, edgeR exhibits a much smaller number of differentially abundant features. In both volcano plots, the housekeeping genes in the main Figure 3 are shown in orange. We can see that these are asymmetrically distributed in both plots. Additionally the location of the features taht DESeq2 identified as having a very large difference are shown in the edgeR volcano plot as blue circles."}

# find housekeeping from ALDEx2

load('analysis/xt.m.Rda')
load('analysis/xt.Rda')
hk.off <- xt.all$diff.win < 2.5 & xt.all$diff.btw > 0 & xt.all$diff.btw < 3

load('analysis/meta.DES.res.Rda')
load('analysis/meta.edge.qlf.Rda')

# these are all very rare K0s
zero.var <-  which(meta.DES.res@listData$lfcSE*sqrt(44) == 0)

weird.des <- which(meta.DES.res@listData$log2FoldChange < -20 )

# housekeeping genes centred with DESeq2 - nice

sig.des <- which(meta.DES.res@listData$padj < 0.01)
sig.edge <- which(p.adjust(meta.edg.qlf$PValue) < 0.01)
par(mfrow=c(2,2))

plot(density(meta.DES.res@listData$log2FoldChange[hk.off]), main='DESeq2 FC')
abline(v=0, col='red', lty=2)

plot(meta.DES.res@listData$log2FoldChange, -1*log10(meta.DES.res@listData$padj), 
  col=rgb(0,0,0,0.1), xlab='log2 Difference', ylab='-1 log10(p.adjust)', main='DESeq2 volcano')
points(meta.DES.res@listData$log2FoldChange[sig.des],-1*log10(meta.DES.res@listData$padj[sig.des] + 1e-70), col='red')
points(meta.DES.res@listData$log2FoldChange[hk.off],-1*log10(meta.DES.res@listData$padj[hk.off] + 1e-70), col='orange', cex=0.6)

plot(density(meta.edg.qlf$logFC[hk.off]), main='edgeR FC')
abline(v=0, col='red', lty=2)

plot(meta.edg.qlf$logFC, -1*log10(p.adjust(meta.edg.qlf$PValue)), 
  col=rgb(0,0,0,0.1), xlab='LFC', ylab='-1log10(p)', main='edgeR volcano')
points(meta.edg.qlf$logFC[sig.edge], -1*log10(p.adjust(meta.edg.qlf$PValue)[sig.edge]), 
  col='red')
points(meta.edg.qlf$logFC[hk.off], -1*log10(p.adjust(meta.edg.qlf$PValue)[hk.off]), 
  col='orange', cex=0.6)
  points(meta.edg.qlf$logFC[weird.des], -1*log10(p.adjust(meta.edg.qlf$PValue)[weird.des]), 
  col='blue', cex=0.6)

```


Examining the plots, edge R clearly not centred with the median housekeeping functions offset by `r median(meta.edg.qlf$logFC[hk.off==T])` and minimum FDR value  is `r min(p.adjust(meta.edg.qlf$PValue)[hk.off==T])`. Additionally, as shown in Figure 4there is little range in the p-values relative to those seen for DESeq2, and the values are more in line with the range seen with ALDEx2.

DESeq2 is better centred with median housekeeping functions offset by `r median(meta.DES.res@listData$log2FoldChange[hk.off==T])` but the minimum FDR value  is `r min(meta.DES.res@listData$padj[hk.off==T])`. In addition there are a large number of functions with 0 variance, these are very low count functions with very high sparsity in the dataset. These are not differential in the DESeq2 analysis. However, there are a number of functions in the DESeq2 analysis that are very differentially abundant, with a log2 fold change of < -20. Examination of the raw counts shows that these are uniformly 0 or 1 in the H dataset, and present at high counts in some, but not all of the BV dataset. That these stand out is odd, since inspection of the count table shows that there are many other functions that are missing from the H dataset, and have higher and more uniform counts in the BV dataset. Thus, the importance of the outlier functions seen in the DESeq2 volcano plot should be viewed with suspicion and may be an artefact of the normalization used. When overplotted on the edgeR volcano plot (blue), it is clear that these functions have non-signficant p-values.

# Checking the scale assumptions of the RLE and TMM normalizations

We can show that the normalizations built into the edgeR Bioconductor package (RLE, TMM, TMMwsp, upperquantile) are scale assumptions by using the normalization factor as an input to `aldex.makeScaleMatrix()` and then measure the mean location of the data as above. The ideal behavior of a normalization is that the mean location of the data should be close to 0 or unchanged. This behavior will ensure that Type 1 and Type 2 errors due to scale assumptions are minimized. 

The results, shown in the tables below compare these normalizations to the no scale assumption (iso) and the geometric mean normalization (GM) assuming that the normalizations are either on a log scale or a linear scale. That these affect scale can be observed by their effect on the mean location of the data. For the most part assuming no scale differences between groups centres the date less well than does the geometric mean. In most cases the other normalizations perform poorer than assuming no scale at all for the rRNA dataset and about as well as the no scale assumption in the metatranscriptome datasets and the single-cell transcriptome dataset. All normalizations perform poorly in the selex dataset. Overall, these results may not be surprising because the TMM and RLE (and related normalizations) were developed specifically to scale and normalize transcriptome datasets [@Robinson:2010a;@Anders:2010], but have become widely used in the analysis of other data modalities; e.g. [@McMurdie:2014a]. 

```{r getNorm, echo=F}
# output from code/scale_norms.R

load('analysis/normalizations.Rda')
knitr::kable(norm.data.out, 'simple', caption='Log scale models')
```

```{r getNormNL, echo=F}
# output from code/scale_norms.R

load('analysis/normalizations.nl.Rda')
knitr::kable(norm.nl.data.out, 'simple', caption='Linear scale models')
```

# References
