\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/BiocStyle/resources/tex/unsrturl}
\@writefile{toc}{\contentsline {section}{\numberline {1}GM is related to Information and Shannon's entropy in HTS datasets}{2}{section.1}}
\newlabel{gm-is-related-to-information-and-shannons-entropy-in-hts-datasets}{{1}{2}{GM is related to Information and Shannon's entropy in HTS datasets}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Shannon's entropy has a volume or size}{2}{subsection.1.1}}
\newlabel{shannons-entropy-has-a-volume-or-size}{{1.1}{2}{Shannon's entropy has a volume or size}{subsection.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Association between entropy (H) and geometric mean (G) as a function of vector length. Twenty random vectors were constructed for each length between 2 and 1000 in increments of 2 for each of the random distributions in the legend; N = Normal, U = Uniform, B = Beta. The bottom right of each plot represents vectors of length 2, and the top left represents the vector of lenght 500. The maximum value of H increases as the vector length increases, and the maximum value of G decreases in lock-step. Each random distribution has an obviously distinct relationship between the two measures. For the purposes of high throughput sequencing the Beta distribution is most similar to that seen in the majority of instances.\relax }}{4}{figure.caption.1}}
\@cons\caption@pkg@list{{ragged2e}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:unnamed-chunk-2}{{1}{4}{Association between entropy (H) and geometric mean (G) as a function of vector length. Twenty random vectors were constructed for each length between 2 and 1000 in increments of 2 for each of the random distributions in the legend; N = Normal, U = Uniform, B = Beta. The bottom right of each plot represents vectors of length 2, and the top left represents the vector of lenght 500. The maximum value of H increases as the vector length increases, and the maximum value of G decreases in lock-step. Each random distribution has an obviously distinct relationship between the two measures. For the purposes of high throughput sequencing the Beta distribution is most similar to that seen in the majority of instances.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plot of the association between H and G at a vector length of 30. The relationship between H and G is inverse, and the strength of that association depends on the distribution. The N distribution shows a very strong assocation, while the Beta distribution is less well defined. Associations are shown for a vector length of 30.\relax }}{5}{figure.caption.2}}
\newlabel{fig:unnamed-chunk-3}{{2}{5}{Plot of the association between H and G at a vector length of 30. The relationship between H and G is inverse, and the strength of that association depends on the distribution. The N distribution shows a very strong assocation, while the Beta distribution is less well defined. Associations are shown for a vector length of 30.\relax }{figure.caption.2}{}}
\gdef \LT@i {\LT@entry 
    {1}{38.33282pt}\LT@entry 
    {2}{44.77803pt}\LT@entry 
    {2}{33.1111pt}\LT@entry 
    {2}{29.77777pt}\LT@entry 
    {2}{33.1111pt}\LT@entry 
    {2}{28.77777pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plot of Shannon's entropy (H) vs geometric mean (G) for each sample in different datasets. The groups that each sample belong to are highlighted as filled or open circles. Each group in each dataset has different entropy with the groups in the selex and metatranscriptome datasets being highly distinct.\relax }}{6}{figure.caption.3}}
\newlabel{fig:info}{{3}{6}{Plot of Shannon's entropy (H) vs geometric mean (G) for each sample in different datasets. The groups that each sample belong to are highlighted as filled or open circles. Each group in each dataset has different entropy with the groups in the selex and metatranscriptome datasets being highly distinct.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Plot of the offset of the mean differnece between groups as a function of scale ratio. For this, the default scale of 1:1 was altered in increments of 0.1 keeping the gamma parameter (dispersion) at 0.5. The filled circle shows the outcome when the calculation is done using the geometric mean and the same gamma parameter.\relax }}{6}{figure.caption.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Effect plots of the selex dataset with various gamma and scale parameters. All scales are calculated with a logNormal distribution to ensure symmetry for the user. \relax }}{8}{figure.caption.5}}
\newlabel{fig:selex}{{5}{8}{Effect plots of the selex dataset with various gamma and scale parameters. All scales are calculated with a logNormal distribution to ensure symmetry for the user. \relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}How scaling affects dispersion}{8}{section.2}}
\newlabel{how-scaling-affects-dispersion}{{2}{8}{How scaling affects dispersion}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces jnk\relax }}{9}{figure.caption.6}}
\newlabel{fig:disp}{{6}{9}{jnk\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Issues with DESeq2 and edgeR}{9}{section.3}}
\newlabel{issues-with-deseq2-and-edger}{{3}{9}{Issues with DESeq2 and edgeR}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Shown here are the mean log2 fold change as a density plot, and a Volcano plot showing the location and adjusted p-value for each feature in the metatranscriptomic dataset. The DESeq2 approach does a good job of centring this data, while edgeR is less suitable. The volcano plots show dramatically different outcomes. The DESeq2 algorithm assigns very large fold changes to features that have only moderate change, and further identifies a very large proportion of features as significantly different. In contrast, edgeR exhibits a much smaller number of differentially abundant features. In both volcano plots, the housekeeping genes in the main Figure 3 are shown in orange. We can see that these are asymmetrically distributed in both plots. Additionally the location of the features taht DESeq2 identified as having a very large difference are shown in the edgeR volcano plot as blue circles.\relax }}{10}{figure.caption.7}}
\newlabel{fig:DESedg}{{7}{10}{Shown here are the mean log2 fold change as a density plot, and a Volcano plot showing the location and adjusted p-value for each feature in the metatranscriptomic dataset. The DESeq2 approach does a good job of centring this data, while edgeR is less suitable. The volcano plots show dramatically different outcomes. The DESeq2 algorithm assigns very large fold changes to features that have only moderate change, and further identifies a very large proportion of features as significantly different. In contrast, edgeR exhibits a much smaller number of differentially abundant features. In both volcano plots, the housekeeping genes in the main Figure 3 are shown in orange. We can see that these are asymmetrically distributed in both plots. Additionally the location of the features taht DESeq2 identified as having a very large difference are shown in the edgeR volcano plot as blue circles.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Checking the scale assumptions of the RLE and TMM normalizations}{10}{section.4}}
\newlabel{checking-the-scale-assumptions-of-the-rle-and-tmm-normalizations}{{4}{10}{Checking the scale assumptions of the RLE and TMM normalizations}{section.4}{}}
\gdef \LT@ii {\LT@entry 
    {3}{29.62466pt}\LT@entry 
    {3}{58.1111pt}\LT@entry 
    {3}{58.1111pt}\LT@entry 
    {3}{58.1111pt}\LT@entry 
    {1}{66.75023pt}\LT@entry 
    {3}{58.1111pt}\LT@entry 
    {3}{52.1111pt}}
\gdef \LT@iii {\LT@entry 
    {3}{29.62466pt}\LT@entry 
    {3}{58.1111pt}\LT@entry 
    {3}{54.77777pt}\LT@entry 
    {3}{58.1111pt}\LT@entry 
    {1}{66.75023pt}\LT@entry 
    {3}{58.1111pt}\LT@entry 
    {3}{52.1111pt}}
\newlabel{tab:getNorm}{{2}{11}{Checking the scale assumptions of the RLE and TMM normalizations}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Log scale models}}{11}{table.2}}
\newlabel{tab:getNormNL}{{3}{11}{Checking the scale assumptions of the RLE and TMM normalizations}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Linear scale models}}{11}{table.3}}
\newlabel{references}{{4}{11}{}{table.3}{}}
\@writefile{toc}{\contentsline {section}{References}{11}{table.3}}
\ttl@finishall
